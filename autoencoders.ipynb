{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c22dba2-d672-4968-9f27-8cde387be124",
   "metadata": {},
   "source": [
    "# Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab78854-df6f-4a2e-a288-a50aebca2f1e",
   "metadata": {},
   "source": [
    "## Import Dependencies and Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "799a0181-8b35-437a-80cf-8776abf960a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.18.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, backend as K, metrics\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from typing import Tuple\n",
    "\n",
    "# Ensure TensorFlow is using the latest version\n",
    "print(f\"TensorFlow Version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8d3cd7-d153-448d-91f8-279fa00c64b5",
   "metadata": {},
   "source": [
    "## Setting Hyper-Parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4e3ebe2-4f61-4d6e-8c5e-f8c959e2dd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define key parameters\n",
    "batch_size = 100\n",
    "original_dim = 784  # 28x28 images flattened\n",
    "latent_dim = 2      # Dimensionality of the latent space\n",
    "intermediate_dim = 256\n",
    "epochs = 50\n",
    "epsilon_std = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8a1deb-7874-4a0c-af3f-fd4d3dd59484",
   "metadata": {},
   "source": [
    "## Sampling helper function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d861c4f-6c14-4373-824c-0f407aaccaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sampling function with type hints\n",
    "def sampling(args: Tuple[tf.Tensor, tf.Tensor]) -> tf.Tensor:\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim), mean=0.0, stddev=epsilon_std)\n",
    "    return z_mean + K.exp(z_log_var / 2) * epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f36e3a-0727-430b-a4e2-6b9e3b885321",
   "metadata": {},
   "source": [
    "## Defining the Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe172bd5-6c42-436c-ae42-e274bf64f089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"encoder\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"encoder\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder_input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_hidden      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">200,960</span> │ encoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ z_mean (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">514</span> │ encoder_hidden[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ z_log_var (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">514</span> │ encoder_hidden[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ z (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ z_mean[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│                     │                   │            │ z_log_var[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder_input       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_hidden      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m200,960\u001b[0m │ encoder_input[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ z_mean (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         │        \u001b[38;5;34m514\u001b[0m │ encoder_hidden[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ z_log_var (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         │        \u001b[38;5;34m514\u001b[0m │ encoder_hidden[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ z (\u001b[38;5;33mLambda\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ z_mean[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│                     │                   │            │ z_log_var[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">201,988</span> (789.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m201,988\u001b[0m (789.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">201,988</span> (789.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m201,988\u001b[0m (789.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build the encoder model\n",
    "# Input layer\n",
    "encoder_input = layers.Input(shape=(original_dim,), name=\"encoder_input\")\n",
    "\n",
    "# Intermediate dense layer\n",
    "encoder_hidden = layers.Dense(intermediate_dim, activation='relu', name=\"encoder_hidden\")(encoder_input)\n",
    "\n",
    "# Mean of the latent space\n",
    "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(encoder_hidden)\n",
    "\n",
    "# Log variance of the latent space\n",
    "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(encoder_hidden)\n",
    "\n",
    "# Sampling layer\n",
    "z = layers.Lambda(sampling, name=\"z\")([z_mean, z_log_var])\n",
    "\n",
    "# Define the encoder model\n",
    "encoder = models.Model(encoder_input, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3452ce86-3272-4539-ac70-3b6349593740",
   "metadata": {},
   "source": [
    "## Defining the Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "005db2f5-a46b-49d2-9fa1-5e23ca43dbb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"decoder\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"decoder\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ decoder_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder_hidden (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">201,488</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ decoder_input (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder_hidden (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │           \u001b[38;5;34m768\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder_output (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │       \u001b[38;5;34m201,488\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">202,256</span> (790.06 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m202,256\u001b[0m (790.06 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">202,256</span> (790.06 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m202,256\u001b[0m (790.06 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build the decoder model\n",
    "# Input for the decoder\n",
    "decoder_input = layers.Input(shape=(latent_dim,), name=\"decoder_input\")\n",
    "\n",
    "# Intermediate dense layer\n",
    "decoder_hidden = layers.Dense(intermediate_dim, activation='relu', name=\"decoder_hidden\")(decoder_input)\n",
    "\n",
    "# Output layer\n",
    "decoder_output = layers.Dense(original_dim, activation='sigmoid', name=\"decoder_output\")(decoder_hidden)\n",
    "\n",
    "# Define the decoder model\n",
    "decoder = models.Model(decoder_input, decoder_output, name=\"decoder\")\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640e68ad-9e5e-4537-9758-7fc9ca09d3e2",
   "metadata": {},
   "source": [
    "## Define the Variational Autoencoder (VAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "549e9520-71a5-44fd-8bfe-2b28d45b8ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom VAE class\n",
    "class VAE(models.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = metrics.Mean(name=\"reconstruction_loss\")\n",
    "        self.kl_loss_tracker = metrics.Mean(name=\"kl_loss\")\n",
    "        \n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        if isinstance(data, tuple):\n",
    "            x = data[0]\n",
    "        else:\n",
    "            x = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Forward pass\n",
    "            z_mean, z_log_var, z = self.encoder(x)\n",
    "            x_decoded = self.decoder(z)\n",
    "            # Compute reconstruction loss using Keras backend binary_crossentropy\n",
    "            reconstruction_loss = K.binary_crossentropy(x, x_decoded)\n",
    "            # reconstruction_loss has shape [batch_size, original_dim]\n",
    "            reconstruction_loss = K.sum(reconstruction_loss, axis=1)  # Sum over features\n",
    "            # Compute KL divergence loss\n",
    "            kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
    "            kl_loss = K.sum(kl_loss, axis=1)\n",
    "            kl_loss *= -0.5\n",
    "            # Total loss\n",
    "            total_loss = K.mean(reconstruction_loss + kl_loss)\n",
    "        # Compute gradients\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        # Update weights\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        # Update metrics\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(K.mean(reconstruction_loss))\n",
    "        self.kl_loss_tracker.update_state(K.mean(kl_loss))\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n",
    "    \n",
    "    def test_step(self, data):\n",
    "        if isinstance(data, tuple):\n",
    "            x = data[0]\n",
    "        else:\n",
    "            x = data\n",
    "        # Forward pass\n",
    "        z_mean, z_log_var, z = self.encoder(x)\n",
    "        x_decoded = self.decoder(z)\n",
    "        # Compute reconstruction loss using Keras backend binary_crossentropy\n",
    "        reconstruction_loss = K.binary_crossentropy(x, x_decoded)\n",
    "        # reconstruction_loss has shape [batch_size, original_dim]\n",
    "        reconstruction_loss = K.sum(reconstruction_loss, axis=1)  # Sum over features\n",
    "        # Compute KL divergence loss\n",
    "        kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
    "        kl_loss = K.sum(kl_loss, axis=1)\n",
    "        kl_loss *= -0.5\n",
    "        # Total loss\n",
    "        total_loss = K.mean(reconstruction_loss + kl_loss)\n",
    "        # Update metrics\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(K.mean(reconstruction_loss))\n",
    "        self.kl_loss_tracker.update_state(K.mean(kl_loss))\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var, z = self.encoder(inputs)\n",
    "        return self.decoder(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3770921b-668f-4c0a-97cf-38bb3b96f1f2",
   "metadata": {},
   "source": [
    "## Initiate the VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a189e59-e66c-49d8-88f8-5e5a8ddbe0e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"vae\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"vae\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ encoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)            │ [(None, 2), (None, 2), │       <span style=\"color: #00af00; text-decoration-color: #00af00\">201,988</span> │\n",
       "│                                 │ (None, 2)]             │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)            │ (None, 784)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">202,256</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ encoder (\u001b[38;5;33mFunctional\u001b[0m)            │ [(None, 2), (None, 2), │       \u001b[38;5;34m201,988\u001b[0m │\n",
       "│                                 │ (None, 2)]             │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder (\u001b[38;5;33mFunctional\u001b[0m)            │ (None, 784)            │       \u001b[38;5;34m202,256\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">404,244</span> (1.54 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m404,244\u001b[0m (1.54 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">404,244</span> (1.54 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m404,244\u001b[0m (1.54 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Instantiate the VAE\n",
    "vae = VAE(encoder, decoder)\n",
    "vae.compile(optimizer='rmsprop')\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc06501b-d853-4743-8fe0-9256ba705fc4",
   "metadata": {},
   "source": [
    "## Define the Dataset - MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31deebb6-30db-4586-aea1-bf64486153a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalize the data to [0, 1] and flatten the images\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "x_train = x_train.reshape((-1, original_dim))\n",
    "x_test = x_test.reshape((-1, original_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564ab2be-d2a7-420a-9399-de7764d795c8",
   "metadata": {},
   "source": [
    "## Train the Variational Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d631006-afce-4334-90c4-b65c8457c709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - kl_loss: 12.4837 - loss: 222.6394 - reconstruction_loss: 210.1556 - val_loss: 173.3471 - val_reconstruction_loss: 168.5719 - val_kl_loss: 4.7752\n",
      "Epoch 2/50\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - kl_loss: 4.7466 - loss: 172.4040 - reconstruction_loss: 167.6574 - val_loss: 168.6217 - val_reconstruction_loss: 163.6448 - val_kl_loss: 4.9769\n",
      "Epoch 3/50\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - kl_loss: 4.9434 - loss: 168.2033 - reconstruction_loss: 163.2599 - val_loss: 165.8716 - val_reconstruction_loss: 160.9848 - val_kl_loss: 4.8868\n",
      "Epoch 4/50\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - kl_loss: 5.0539 - loss: 165.2634 - reconstruction_loss: 160.2095 - val_loss: 163.7493 - val_reconstruction_loss: 158.6940 - val_kl_loss: 5.0553\n",
      "Epoch 5/50\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - kl_loss: 5.1320 - loss: 163.4388 - reconstruction_loss: 158.3068 - val_loss: 162.8536 - val_reconstruction_loss: 157.7390 - val_kl_loss: 5.1145\n",
      "Epoch 6/50\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - kl_loss: 5.1567 - loss: 162.1628 - reconstruction_loss: 157.0061 - val_loss: 161.8364 - val_reconstruction_loss: 156.6486 - val_kl_loss: 5.1878\n",
      "Epoch 7/50\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - kl_loss: 5.2199 - loss: 161.4426 - reconstruction_loss: 156.2227 - val_loss: 160.7076 - val_reconstruction_loss: 155.4174 - val_kl_loss: 5.2901\n",
      "Epoch 8/50\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - kl_loss: 5.2718 - loss: 160.2607 - reconstruction_loss: 154.9889 - val_loss: 160.1629 - val_reconstruction_loss: 154.8545 - val_kl_loss: 5.3084\n",
      "Epoch 9/50\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - kl_loss: 5.3098 - loss: 159.7079 - reconstruction_loss: 154.3982 - val_loss: 159.7085 - val_reconstruction_loss: 154.2715 - val_kl_loss: 5.4370\n",
      "Epoch 10/50\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - kl_loss: 5.3470 - loss: 159.1715 - reconstruction_loss: 153.8245 - val_loss: 159.3415 - val_reconstruction_loss: 153.9638 - val_kl_loss: 5.3777\n",
      "Epoch 11/50\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - kl_loss: 5.4031 - loss: 158.5639 - reconstruction_loss: 153.1608 - val_loss: 158.7808 - val_reconstruction_loss: 153.2753 - val_kl_loss: 5.5056\n",
      "Epoch 12/50\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - kl_loss: 5.4132 - loss: 157.8117 - reconstruction_loss: 152.3985 - val_loss: 158.3402 - val_reconstruction_loss: 152.8850 - val_kl_loss: 5.4552\n",
      "Epoch 13/50\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - kl_loss: 5.4384 - loss: 157.9653 - reconstruction_loss: 152.5269 - val_loss: 158.0536 - val_reconstruction_loss: 152.5995 - val_kl_loss: 5.4541\n",
      "Epoch 14/50\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - kl_loss: 5.4782 - loss: 157.4651 - reconstruction_loss: 151.9870 - val_loss: 157.7554 - val_reconstruction_loss: 152.4446 - val_kl_loss: 5.3108\n",
      "Epoch 15/50\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - kl_loss: 5.5227 - loss: 156.8098 - reconstruction_loss: 151.2871 - val_loss: 157.5959 - val_reconstruction_loss: 152.0641 - val_kl_loss: 5.5317\n",
      "Epoch 16/50\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - kl_loss: 5.5567 - loss: 156.4234 - reconstruction_loss: 150.8667 - val_loss: 157.0270 - val_reconstruction_loss: 151.3454 - val_kl_loss: 5.6816\n",
      "Epoch 17/50\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - kl_loss: 5.5691 - loss: 156.2585 - reconstruction_loss: 150.6894 - val_loss: 156.6163 - val_reconstruction_loss: 151.0653 - val_kl_loss: 5.5510\n",
      "Epoch 18/50\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - kl_loss: 5.6144 - loss: 155.8026 - reconstruction_loss: 150.1882 - val_loss: 156.6791 - val_reconstruction_loss: 151.1297 - val_kl_loss: 5.5493\n",
      "Epoch 19/50\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - kl_loss: 5.6077 - loss: 155.6299 - reconstruction_loss: 150.0221 - val_loss: 156.5009 - val_reconstruction_loss: 150.8326 - val_kl_loss: 5.6684\n",
      "Epoch 20/50\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - kl_loss: 5.6369 - loss: 155.3804 - reconstruction_loss: 149.7435 - val_loss: 155.8633 - val_reconstruction_loss: 150.2555 - val_kl_loss: 5.6078\n",
      "Epoch 21/50\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - kl_loss: 5.6649 - loss: 154.8571 - reconstruction_loss: 149.1922 - val_loss: 156.0909 - val_reconstruction_loss: 150.4377 - val_kl_loss: 5.6532\n",
      "Epoch 22/50\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - kl_loss: 5.6935 - loss: 154.5623 - reconstruction_loss: 148.8688 - val_loss: 155.6034 - val_reconstruction_loss: 149.9561 - val_kl_loss: 5.6473\n",
      "Epoch 23/50\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - kl_loss: 5.7136 - loss: 154.3833 - reconstruction_loss: 148.6697 - val_loss: 155.7307 - val_reconstruction_loss: 150.0796 - val_kl_loss: 5.6511\n",
      "Epoch 24/50\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - kl_loss: 5.7275 - loss: 154.1473 - reconstruction_loss: 148.4198 - val_loss: 155.3585 - val_reconstruction_loss: 149.5499 - val_kl_loss: 5.8086\n",
      "Epoch 25/50\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - kl_loss: 5.7563 - loss: 154.2478 - reconstruction_loss: 148.4915 - val_loss: 155.3597 - val_reconstruction_loss: 149.6902 - val_kl_loss: 5.6694\n",
      "Epoch 26/50\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - kl_loss: 5.7611 - loss: 153.8948 - reconstruction_loss: 148.1337 - val_loss: 154.9753 - val_reconstruction_loss: 149.2316 - val_kl_loss: 5.7437\n",
      "Epoch 27/50\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - kl_loss: 5.7823 - loss: 153.1145 - reconstruction_loss: 147.3321 - val_loss: 154.8652 - val_reconstruction_loss: 149.2692 - val_kl_loss: 5.5960\n",
      "Epoch 28/50\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - kl_loss: 5.7980 - loss: 153.3313 - reconstruction_loss: 147.5333 - val_loss: 154.8471 - val_reconstruction_loss: 149.0874 - val_kl_loss: 5.7598\n",
      "Epoch 29/50\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - kl_loss: 5.8059 - loss: 153.3371 - reconstruction_loss: 147.5312 - val_loss: 154.5290 - val_reconstruction_loss: 148.6924 - val_kl_loss: 5.8366\n",
      "Epoch 30/50\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - kl_loss: 5.8074 - loss: 153.1125 - reconstruction_loss: 147.3050 - val_loss: 154.6794 - val_reconstruction_loss: 148.8585 - val_kl_loss: 5.8208\n",
      "Epoch 31/50\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - kl_loss: 5.8335 - loss: 152.6420 - reconstruction_loss: 146.8085 - val_loss: 154.5295 - val_reconstruction_loss: 148.6590 - val_kl_loss: 5.8705\n",
      "Epoch 32/50\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - kl_loss: 5.8514 - loss: 152.4708 - reconstruction_loss: 146.6194 - val_loss: 154.3045 - val_reconstruction_loss: 148.4330 - val_kl_loss: 5.8715\n",
      "Epoch 33/50\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - kl_loss: 5.8698 - loss: 152.3293 - reconstruction_loss: 146.4595 - val_loss: 154.6297 - val_reconstruction_loss: 148.9107 - val_kl_loss: 5.7189\n",
      "Epoch 34/50\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - kl_loss: 5.8495 - loss: 152.3481 - reconstruction_loss: 146.4985 - val_loss: 154.1419 - val_reconstruction_loss: 148.3966 - val_kl_loss: 5.7453\n",
      "Epoch 35/50\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - kl_loss: 5.8844 - loss: 152.4284 - reconstruction_loss: 146.5441 - val_loss: 154.5171 - val_reconstruction_loss: 148.6254 - val_kl_loss: 5.8917\n",
      "Epoch 36/50\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - kl_loss: 5.9154 - loss: 151.7916 - reconstruction_loss: 145.8761 - val_loss: 153.8567 - val_reconstruction_loss: 148.1115 - val_kl_loss: 5.7452\n",
      "Epoch 37/50\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - kl_loss: 5.8866 - loss: 152.0726 - reconstruction_loss: 146.1860 - val_loss: 154.0487 - val_reconstruction_loss: 148.0697 - val_kl_loss: 5.9790\n",
      "Epoch 38/50\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - kl_loss: 5.9103 - loss: 152.1550 - reconstruction_loss: 146.2447 - val_loss: 153.7375 - val_reconstruction_loss: 147.8462 - val_kl_loss: 5.8913\n",
      "Epoch 39/50\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - kl_loss: 5.9127 - loss: 151.7487 - reconstruction_loss: 145.8360 - val_loss: 153.6858 - val_reconstruction_loss: 147.7766 - val_kl_loss: 5.9092\n",
      "Epoch 40/50\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - kl_loss: 5.9518 - loss: 151.3736 - reconstruction_loss: 145.4219 - val_loss: 153.6708 - val_reconstruction_loss: 147.8162 - val_kl_loss: 5.8547\n",
      "Epoch 41/50\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - kl_loss: 5.9345 - loss: 151.5496 - reconstruction_loss: 145.6150 - val_loss: 153.7464 - val_reconstruction_loss: 147.7386 - val_kl_loss: 6.0077\n",
      "Epoch 42/50\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - kl_loss: 5.9693 - loss: 150.9411 - reconstruction_loss: 144.9719 - val_loss: 153.6975 - val_reconstruction_loss: 147.8846 - val_kl_loss: 5.8130\n",
      "Epoch 43/50\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - kl_loss: 5.9636 - loss: 151.0896 - reconstruction_loss: 145.1259 - val_loss: 153.8506 - val_reconstruction_loss: 147.8540 - val_kl_loss: 5.9966\n",
      "Epoch 44/50\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - kl_loss: 5.9802 - loss: 151.0771 - reconstruction_loss: 145.0970 - val_loss: 153.6729 - val_reconstruction_loss: 147.5116 - val_kl_loss: 6.1613\n",
      "Epoch 45/50\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - kl_loss: 5.9932 - loss: 150.6414 - reconstruction_loss: 144.6481 - val_loss: 153.8428 - val_reconstruction_loss: 147.9933 - val_kl_loss: 5.8495\n",
      "Epoch 46/50\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - kl_loss: 5.9963 - loss: 150.5933 - reconstruction_loss: 144.5970 - val_loss: 153.5225 - val_reconstruction_loss: 147.5713 - val_kl_loss: 5.9512\n",
      "Epoch 47/50\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - kl_loss: 6.0147 - loss: 150.6022 - reconstruction_loss: 144.5875 - val_loss: 153.2473 - val_reconstruction_loss: 147.2454 - val_kl_loss: 6.0019\n",
      "Epoch 48/50\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - kl_loss: 6.0049 - loss: 150.7849 - reconstruction_loss: 144.7801 - val_loss: 153.3252 - val_reconstruction_loss: 147.3713 - val_kl_loss: 5.9539\n",
      "Epoch 49/50\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - kl_loss: 6.0271 - loss: 150.3209 - reconstruction_loss: 144.2938 - val_loss: 153.1711 - val_reconstruction_loss: 147.2457 - val_kl_loss: 5.9254\n",
      "Epoch 50/50\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - kl_loss: 6.0345 - loss: 150.0937 - reconstruction_loss: 144.0592 - val_loss: 153.3971 - val_reconstruction_loss: 147.3028 - val_kl_loss: 6.0943\n"
     ]
    }
   ],
   "source": [
    "# Train the VAE\n",
    "history = vae.fit(\n",
    "    x_train,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    validation_data=(x_test, None)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901d6e69-a8a2-4e3b-9408-372d8db42df0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9450d9d4-88b1-46a0-9619-7167496e67a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083130aa-ce11-463d-84ed-b81de4d4e3f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (env)",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
