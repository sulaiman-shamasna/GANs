{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc509a10-2f26-4f29-897b-253a4b4f4957",
   "metadata": {},
   "source": [
    "# Wasserstein Generative Adversarial Network - WGAN\n",
    "---\n",
    "The Wasserstein GAN, or WGAN for short, was introduced by Martin Arjovsky, et al. in their 2017 paper titled [Wasserstein GAN](https://arxiv.org/abs/1701.07875).\n",
    "\n",
    "The Wasserstein GAN (WGAN) extends the traditional GAN by introducing an alternative approach to training the generator. Its goal is to improve the generator's ability to approximate the data distribution observed in the training dataset.\n",
    "\n",
    "Rather than using a discriminator to classify generated images as real or fake, the WGAN replaces it with a critic. The critic evaluates images by scoring their \"realness\" or \"fakeness,\" providing a continuous metric instead of binary classification.\n",
    "\n",
    "This modification is based on a theoretical principle: training the generator should minimize the distance between the data distribution in the training set and the distribution of generated samples.\n",
    "\n",
    "WGAN offers several advantages. Its training process is more stable, less sensitive to model architecture, and less dependent on hyperparameter configurations. Most importantly, the critic's loss correlates with the quality of images produced by the generator, making it a more reliable indicator of training progress."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ffe0b3",
   "metadata": {},
   "source": [
    "## Wasserstein GAN Implementation Details\n",
    "---\n",
    "Although the theoretical grounding for the WGAN is dense, the implementation of a WGAN requires a few minor changes to the standard Deep Convolutional GAN, or DCGAN.\n",
    "\n",
    "The image below provides a summary of the main training loop for training a WGAN, taken from the paper. Note the listing of recommended hyperparameters used in the model.\n",
    "\n",
    "\n",
    "![gan-algorithm](plots/wgan-algorithm.png)\n",
    "\n",
    "The differences in implementation for the WGAN are as follows:\n",
    "\n",
    "1. Use a linear activation function in the output layer of the critic model (instead of sigmoid).\n",
    "2. Use -1 labels for real images and 1 labels for fake images (instead of 1 and 0).\n",
    "3. Use Wasserstein loss to train the critic and generator models.\n",
    "4. Constrain critic model weights to a limited range after each mini batch update (e.g. [-0.01,0.01]).\n",
    "5. Update the critic model more times than the generator each iteration (e.g. 5).\n",
    "6. Use the RMSProp version of gradient descent with a small learning rate and no momentum (e.g. 0.00005).\n",
    "\n",
    "**NOTE** This code will to some extend be a modified version of that implemented in the [DCGAN](https://github.com/sulaiman-shamasna/GANs/blob/main/DCGANs.ipynb) notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a9a2c2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "da47a1bf-3d17-4242-894d-32166f722ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import expand_dims\n",
    "from numpy import mean\n",
    "from numpy import ones\n",
    "from numpy.random import randn\n",
    "from numpy.random import randint\n",
    "from keras.datasets.mnist import load_data\n",
    "from keras import backend\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.constraints import Constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "81ebcb45-ebe9-40c9-a4cc-d1e43685f3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c4727856-2270-4777-a6ca-2ae71a18cfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clip model weights to a given hypercube\n",
    "class ClipConstraint(Constraint):\n",
    "\t# set clip value when initialized\n",
    "\tdef __init__(self, clip_value):\n",
    "\t\tself.clip_value = clip_value\n",
    " \n",
    "\t# clip model weights to hypercube\n",
    "\tdef __call__(self, weights):\n",
    "\t\treturn backend.clip(weights, -self.clip_value, self.clip_value)\n",
    " \n",
    "\t# get the config\n",
    "\tdef get_config(self):\n",
    "\t\treturn {'clip_value': self.clip_value}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "27067c3f-b2f8-418d-8d9d-a0d9c81faa20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define the Wasserstein loss function\n",
    "def wasserstein_loss(y_true, y_pred):\n",
    "    return tf.reduce_mean(y_true * y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59ad77e",
   "metadata": {},
   "source": [
    "## How to Train a Wasserstein GAN Model\n",
    "---\n",
    "Now that we know the specific implementation details for the WGAN, we can implement the model for image generation.\n",
    "\n",
    "In this section, we will develop a WGAN to generate a single handwritten digit (‘7’) from the [MNIST dataset](https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-fashion-mnist-clothing-classification/). This is a good test problem for the WGAN as it is a small dataset requiring a modest mode that is quick to train.\n",
    "\n",
    "The first step is to define the models.\n",
    "\n",
    "The critic model takes as input one 28×28 grayscale image and outputs a score for the realness or fakeness of the image. It is implemented as a modest convolutional neural network using best practices for DCGAN design such as using the [LeakyReLU activation](https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/) function with a slope of 0.2, [batch normalization](https://machinelearningmastery.com/how-to-accelerate-learning-of-deep-neural-networks-with-batch-normalization/), and using a [2×2 stride to downsample](https://machinelearningmastery.com/padding-and-stride-for-convolutional-neural-networks/).\n",
    "\n",
    "The critic model makes use of the new ClipConstraint weight constraint to clip model weights after mini-batch updates and is optimized using the custom wasserstein_loss() function, the RMSProp version of stochastic gradient descent with a learning rate of 0.00005.\n",
    "\n",
    "The ```define_critic()``` function below implements this, defining and compiling the critic model and returning it. The input shape of the image is parameterized as a default function argument to make it clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "81f2e591-31ee-4e60-aad0-f92f368d193d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the standalone critic model\n",
    "def define_critic(in_shape=(28,28,1)):\n",
    "\t# weight initialization\n",
    "\tinit = RandomNormal(stddev=0.02)\n",
    "\t# weight constraint\n",
    "\tconst = ClipConstraint(0.01)\n",
    "\t# define model\n",
    "\tmodel = Sequential()\n",
    "\t# downsample to 14x14\n",
    "\tmodel.add(Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init, kernel_constraint=const, input_shape=in_shape))\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(LeakyReLU(alpha=0.2))\n",
    "\t# downsample to 7x7\n",
    "\tmodel.add(Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init, kernel_constraint=const))\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(LeakyReLU(alpha=0.2))\n",
    "\t# scoring, linear activation\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(1))\n",
    "\t# compile model\n",
    "\topt = RMSprop(learning_rate=0.00005)\n",
    "\tmodel.compile(loss=wasserstein_loss, optimizer=opt)\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "37c13c3a-b148-4215-9130-5feecb9a021d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_8\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,088</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_12          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_13          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3136</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,137</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │         \u001b[38;5;34m1,088\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_12          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_14 (\u001b[38;5;33mLeakyReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │        \u001b[38;5;34m65,600\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_13          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_15 (\u001b[38;5;33mLeakyReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_4 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3136\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │         \u001b[38;5;34m3,137\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">70,337</span> (274.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m70,337\u001b[0m (274.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">70,081</span> (273.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m70,081\u001b[0m (273.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> (1.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m256\u001b[0m (1.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "define_critic().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95dd834",
   "metadata": {},
   "source": [
    "The generator model takes as input a point in the latent space and outputs a single 28×28 grayscale image.\n",
    "\n",
    "This is achieved by using a fully connected layer to interpret the point in the latent space and provide sufficient activations that can be reshaped into many copies (in this case, 128) of a low-resolution version of the output image (e.g. 7×7). This is then upsampled two times, doubling the size and quadrupling the area of the activations each time using transpose convolutional layers.\n",
    "\n",
    "The model uses best practices such as the LeakyReLU activation, a kernel size that is a factor of the stride size, and a hyperbolic tangent (tanh) activation function in the output layer.\n",
    "\n",
    "The define_generator() function below defines the generator model but intentionally does not compile it as it is not trained directly, then returns the model. The size of the latent space is parameterized as a function argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bdbd1e44-5188-4cc0-b1ec-720596795f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the standalone generator model\n",
    "def define_generator(latent_dim):\n",
    "\t# weight initialization\n",
    "\tinit = RandomNormal(stddev=0.02)\n",
    "\t# define model\n",
    "\tmodel = Sequential()\n",
    "\t# foundation for 7x7 image\n",
    "\tn_nodes = 128 * 7 * 7\n",
    "\tmodel.add(Dense(n_nodes, kernel_initializer=init, input_dim=latent_dim))\n",
    "\tmodel.add(LeakyReLU(alpha=0.2))\n",
    "\tmodel.add(Reshape((7, 7, 128)))\n",
    "\t# upsample to 14x14\n",
    "\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init))\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(LeakyReLU(alpha=0.2))\n",
    "\t# upsample to 28x28\n",
    "\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init))\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(LeakyReLU(alpha=0.2))\n",
    "\t# output 28x28x1\n",
    "\tmodel.add(Conv2D(1, (7,7), activation='tanh', padding='same', kernel_initializer=init))\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0938dcd",
   "metadata": {},
   "source": [
    "Next, a GAN model can be defined that combines both the generator model and the critic model into one larger model.\n",
    "\n",
    "This larger model will be used to train the model weights in the generator, using the output and error calculated by the critic model. The critic model is trained separately, and as such, the model weights are marked as not trainable in this larger GAN model to ensure that only the weights of the generator model are updated. This change to the trainability of the critic weights only has an effect when training the combined GAN model, not when training the critic standalone.\n",
    "\n",
    "This larger GAN model takes as input a point in the latent space, uses the generator model to generate an image, which is fed as input to the critic model, then output scored as real or fake. The model is fit using RMSProp with the custom wasserstein_loss() function.\n",
    "\n",
    "The define_gan() function below implements this, taking the already defined generator and critic models as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "03779182-aaff-4dd9-90fd-c8b0ff472cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the combined generator and critic model, for updating the generator\n",
    "def define_gan(generator, critic):\n",
    "\t# make weights in the critic not trainable\n",
    "\tfor layer in critic.layers:\n",
    "\t\tif not isinstance(layer, BatchNormalization):\n",
    "\t\t\tlayer.trainable = False\n",
    "\t# connect them\n",
    "\tmodel = Sequential()\n",
    "\t# add generator\n",
    "\tmodel.add(generator)\n",
    "\t# add the critic\n",
    "\tmodel.add(critic)\n",
    "\t# compile model\n",
    "\topt = RMSprop(learning_rate=0.00005)\n",
    "\tmodel.compile(loss=wasserstein_loss, optimizer=opt)\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a037f3d6",
   "metadata": {},
   "source": [
    "Now that we have defined the GAN model, we need to train it. But, before we can train the model, we require input data.\n",
    "\n",
    "The first step is to load and [scale the MNIST dataset](https://machinelearningmastery.com/how-to-manually-scale-image-pixel-data-for-deep-learning/). The whole dataset is loaded via a call to the load_data() Keras function, then a subset of the images is selected (about 5,000) that belongs to class 7, e.g. are a handwritten depiction of the number seven. Then the pixel values must be scaled to the range [-1,1] to match the output of the generator model.\n",
    "\n",
    "The ```load_real_samples()``` function below implements this, returning the loaded and scaled subset of the MNIST training dataset ready for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e7e1119a-e404-4bef-a2b0-ac863b226943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images\n",
    "def load_real_samples():\n",
    "\t# load dataset\n",
    "\t(trainX, trainy), (_, _) = load_data()\n",
    "\t# select all of the examples for a given class\n",
    "\tselected_ix = trainy == 7\n",
    "\tX = trainX[selected_ix]\n",
    "\t# expand to 3d, e.g. add channels\n",
    "\tX = expand_dims(X, axis=-1)\n",
    "\t# convert from ints to floats\n",
    "\tX = X.astype('float32')\n",
    "\t# scale from [0,255] to [-1,1]\n",
    "\tX = (X - 127.5) / 127.5\n",
    "\treturn X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b46d695",
   "metadata": {},
   "source": [
    "We will require one batch (or a half) batch of real images from the dataset each update to the GAN model. A simple way to achieve this is to select a [random sample](https://machinelearningmastery.com/how-to-generate-random-numbers-in-python/) of images from the dataset each time.\n",
    "\n",
    "The ```generate_real_samples()``` function below implements this, taking the prepared dataset as an argument, selecting and returning a random sample of images and their corresponding label for the critic, specifically target=-1 indicating that they are real images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d570c6b5-7b80-44ac-a1df-c4d74f8461aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select real samples\n",
    "def generate_real_samples(dataset, n_samples):\n",
    "\t# choose random instances\n",
    "\tix = randint(0, dataset.shape[0], n_samples)\n",
    "\t# select images\n",
    "\tX = dataset[ix]\n",
    "\t# generate class labels, -1 for 'real'\n",
    "\ty = -ones((n_samples, 1))\n",
    "\treturn X, y\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5dc5cf4d-2c07-4d19-af24-1e734f611dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate points in latent space as input for the generator\n",
    "def generate_latent_points(latent_dim, n_samples):\n",
    "\t# generate points in the latent space\n",
    "\tx_input = randn(latent_dim * n_samples)\n",
    "\t# reshape into a batch of inputs for the network\n",
    "\tx_input = x_input.reshape(n_samples, latent_dim)\n",
    "\treturn x_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "eb2b1855-862e-43a3-ae91-2ddc3a4b16ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the generator to generate n fake examples, with class labels\n",
    "def generate_fake_samples(generator, latent_dim, n_samples):\n",
    "    # generate points in latent space\n",
    "    x_input = generate_latent_points(latent_dim, n_samples)\n",
    "    # directly call the generator\n",
    "    X = generator(x_input, training=False)\n",
    "    # create class labels with 1.0 for 'fake'\n",
    "    y = tf.ones((n_samples, 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e60be09c-a063-4e32-a9f0-7cd054cb038d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# generate samples and save as a plot and save the model\n",
    "def summarize_performance(step, g_model, latent_dim, n_samples=100):\n",
    "\t# prepare fake examples\n",
    "\tX, _ = generate_fake_samples(g_model, latent_dim, n_samples)\n",
    "\t# scale from [-1,1] to [0,1]\n",
    "\tX = (X + 1) / 2.0\n",
    "\t# plot images\n",
    "\tfor i in range(10 * 10):\n",
    "\t\t# define subplot\n",
    "\t\tpyplot.subplot(10, 10, 1 + i)\n",
    "\t\t# turn off axis\n",
    "\t\tpyplot.axis('off')\n",
    "\t\t# plot raw pixel data\n",
    "\t\tpyplot.imshow(X[i, :, :, 0], cmap='gray_r')\n",
    "\t# save plot to file\n",
    "\tfilename1 = 'generated_plot_%04d.png' % (step+1)\n",
    "\tfilename1_dir = os.path.join('wgan_results', filename1)\t\n",
    "\tpyplot.savefig(filename1_dir)\n",
    "\tpyplot.close()\n",
    "\t# save the generator model\n",
    "\tfilename2 = 'model_%04d.h5' % (step+1)\n",
    "\tfilename2_dir = os.path.join('wgan_results', filename2)\n",
    "\tg_model.save(filename2_dir)\n",
    "\tprint('>Saved: %s and %s' % (filename1, filename2_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "91aedc74-c4df-4118-9645-f8e8b386d250",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "result_path = os.path.join('wgan_results', 'plot_line_plot_loss.png')\n",
    "# create a line plot of loss for the gan and save to file\n",
    "def plot_history(d1_hist, d2_hist, g_hist):\n",
    "\t# plot history\n",
    "\tpyplot.plot(d1_hist, label='crit_real')\n",
    "\tpyplot.plot(d2_hist, label='crit_fake')\n",
    "\tpyplot.plot(g_hist, label='gen')\n",
    "\tpyplot.legend(result_path)\n",
    "\tpyplot.savefig()\n",
    "\tpyplot.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3cefe3e3-3345-4890-83df-4e7a89f6b35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimizers outside of the train_step function\n",
    "critic_optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.00005)\n",
    "generator_optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.00005)\n",
    "\n",
    "@tf.function\n",
    "def train_step(g_model, c_model, gan_model, real_images, latent_dim, n_batch, n_critic, critic_optimizer, generator_optimizer):\n",
    "    c1_losses, c2_losses = [], []\n",
    "\n",
    "    # Train the critic more frequently than the generator\n",
    "    for _ in range(n_critic):\n",
    "        # Generate fake images\n",
    "        fake_images, y_fake = generate_fake_samples(g_model, latent_dim, n_batch // 2)\n",
    "        y_real = -tf.ones((n_batch // 2, 1))  # Label for real images in WGAN\n",
    "\n",
    "        # Update critic on real images\n",
    "        with tf.GradientTape() as c_tape:\n",
    "            real_output = c_model(real_images, training=True)\n",
    "            fake_output = c_model(fake_images, training=True)\n",
    "            c_loss = tf.reduce_mean(fake_output) - tf.reduce_mean(real_output)\n",
    "\n",
    "        # Apply gradients to critic\n",
    "        c_gradients = c_tape.gradient(c_loss, c_model.trainable_variables)\n",
    "        critic_optimizer.apply_gradients(zip(c_gradients, c_model.trainable_variables))\n",
    "        c1_losses.append(c_loss)\n",
    "\n",
    "    # Prepare latent points and inverted labels for generator update\n",
    "    latent_points = generate_latent_points(latent_dim, n_batch)\n",
    "    y_gan = -tf.ones((n_batch, 1))\n",
    "\n",
    "    # Update generator via critic’s loss\n",
    "    with tf.GradientTape() as g_tape:\n",
    "        generated_images = g_model(latent_points, training=True)\n",
    "        fake_output = c_model(generated_images, training=False)\n",
    "        g_loss = -tf.reduce_mean(fake_output)\n",
    "\n",
    "    # Apply gradients to generator\n",
    "    g_gradients = g_tape.gradient(g_loss, g_model.trainable_variables)\n",
    "    generator_optimizer.apply_gradients(zip(g_gradients, g_model.trainable_variables))\n",
    "    c2_losses.append(g_loss)\n",
    "\n",
    "    return tf.reduce_mean(c1_losses), tf.reduce_mean(c2_losses), g_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "317a26ef-25e3-4df4-9ae9-efd39a8f1090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the generator and critic\n",
    "def train(g_model, c_model, gan_model, dataset, latent_dim, n_epochs=10, n_batch=64, n_critic=5):\n",
    "    bat_per_epo = int(dataset.shape[0] / n_batch)\n",
    "    n_steps = bat_per_epo * n_epochs\n",
    "    \n",
    "    # Lists for keeping track of loss\n",
    "    c1_hist, c2_hist, g_hist = list(), list(), list()\n",
    "    \n",
    "    for i in range(n_steps):\n",
    "        # Get randomly selected 'real' samples\n",
    "        X_real, y_real = generate_real_samples(dataset, n_batch // 2)\n",
    "        \n",
    "        # Perform a training step\n",
    "        c1_loss, c2_loss, g_loss = train_step(g_model, c_model, gan_model, X_real, latent_dim, n_batch, n_critic, critic_optimizer, generator_optimizer)\n",
    "        \n",
    "        # Track losses\n",
    "        c1_hist.append(c1_loss)\n",
    "        c2_hist.append(c2_loss)\n",
    "        g_hist.append(g_loss)\n",
    "        \n",
    "        print(f'>{i+1}, c1={c1_loss:.3f}, c2={c2_loss:.3f}, g={g_loss:.3f}')\n",
    "        \n",
    "        # Summarize performance\n",
    "        if (i+1) % bat_per_epo == 0:\n",
    "            summarize_performance(i, g_model, latent_dim)\n",
    "    \n",
    "    plot_history(c1_hist, c2_hist, g_hist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5f5384ae-41a2-4a70-ac81-c02656da63df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6265, 28, 28, 1)\n",
      ">1, c1=1.155, c2=0.027, g=0.027\n",
      ">2, c1=1.044, c2=0.005, g=0.005\n",
      ">3, c1=1.314, c2=-0.012, g=-0.012\n",
      ">4, c1=1.289, c2=-0.031, g=-0.031\n",
      ">5, c1=1.578, c2=-0.055, g=-0.055\n",
      ">6, c1=1.317, c2=-0.085, g=-0.085\n",
      ">7, c1=1.667, c2=-0.123, g=-0.123\n",
      ">8, c1=1.934, c2=-0.165, g=-0.165\n",
      ">9, c1=1.904, c2=-0.207, g=-0.207\n",
      ">10, c1=2.086, c2=-0.252, g=-0.252\n",
      ">11, c1=1.952, c2=-0.305, g=-0.305\n",
      ">12, c1=2.197, c2=-0.370, g=-0.370\n",
      ">13, c1=1.906, c2=-0.438, g=-0.438\n",
      ">14, c1=2.114, c2=-0.509, g=-0.509\n",
      ">15, c1=2.229, c2=-0.586, g=-0.586\n",
      ">16, c1=2.160, c2=-0.683, g=-0.683\n",
      ">17, c1=2.731, c2=-0.789, g=-0.789\n",
      ">18, c1=2.837, c2=-0.908, g=-0.908\n",
      ">19, c1=2.498, c2=-1.027, g=-1.027\n",
      ">20, c1=2.819, c2=-1.159, g=-1.159\n",
      ">21, c1=2.756, c2=-1.303, g=-1.303\n",
      ">22, c1=2.752, c2=-1.453, g=-1.453\n",
      ">23, c1=2.901, c2=-1.646, g=-1.646\n",
      ">24, c1=3.150, c2=-1.827, g=-1.827\n",
      ">25, c1=3.231, c2=-2.029, g=-2.029\n",
      ">26, c1=3.011, c2=-2.244, g=-2.244\n",
      ">27, c1=2.902, c2=-2.518, g=-2.518\n",
      ">28, c1=3.148, c2=-2.826, g=-2.826\n",
      ">29, c1=2.968, c2=-3.128, g=-3.128\n",
      ">30, c1=3.032, c2=-3.458, g=-3.458\n",
      ">31, c1=3.016, c2=-3.792, g=-3.792\n",
      ">32, c1=3.272, c2=-4.144, g=-4.144\n",
      ">33, c1=3.304, c2=-4.510, g=-4.510\n",
      ">34, c1=3.345, c2=-4.931, g=-4.931\n",
      ">35, c1=3.543, c2=-5.335, g=-5.335\n",
      ">36, c1=3.328, c2=-5.829, g=-5.829\n",
      ">37, c1=3.861, c2=-6.302, g=-6.302\n",
      ">38, c1=4.049, c2=-6.867, g=-6.867\n",
      ">39, c1=3.582, c2=-7.439, g=-7.439\n",
      ">40, c1=4.033, c2=-8.060, g=-8.060\n",
      ">41, c1=3.843, c2=-8.702, g=-8.702\n",
      ">42, c1=3.811, c2=-9.371, g=-9.371\n",
      ">43, c1=3.918, c2=-10.056, g=-10.056\n",
      ">44, c1=3.901, c2=-10.744, g=-10.744\n",
      ">45, c1=4.278, c2=-11.479, g=-11.479\n",
      ">46, c1=3.937, c2=-12.230, g=-12.230\n",
      ">47, c1=3.972, c2=-13.041, g=-13.041\n",
      ">48, c1=4.083, c2=-13.879, g=-13.879\n",
      ">49, c1=4.451, c2=-14.747, g=-14.747\n",
      ">50, c1=4.088, c2=-15.611, g=-15.611\n",
      ">51, c1=4.236, c2=-16.485, g=-16.485\n",
      ">52, c1=4.169, c2=-17.430, g=-17.430\n",
      ">53, c1=4.476, c2=-18.370, g=-18.370\n",
      ">54, c1=4.620, c2=-19.357, g=-19.357\n",
      ">55, c1=4.474, c2=-20.177, g=-20.177\n",
      ">56, c1=4.465, c2=-20.947, g=-20.947\n",
      ">57, c1=4.687, c2=-21.966, g=-21.966\n",
      ">58, c1=4.490, c2=-23.207, g=-23.207\n",
      ">59, c1=4.513, c2=-24.289, g=-24.289\n",
      ">60, c1=4.727, c2=-25.349, g=-25.349\n",
      ">61, c1=4.340, c2=-26.275, g=-26.275\n",
      ">62, c1=4.669, c2=-27.167, g=-27.167\n",
      ">63, c1=4.641, c2=-28.157, g=-28.157\n",
      ">64, c1=4.866, c2=-29.099, g=-29.099\n",
      ">65, c1=4.477, c2=-30.078, g=-30.078\n",
      ">66, c1=4.583, c2=-30.982, g=-30.982\n",
      ">67, c1=4.818, c2=-31.814, g=-31.814\n",
      ">68, c1=4.882, c2=-32.577, g=-32.577\n",
      ">69, c1=4.704, c2=-33.424, g=-33.424\n",
      ">70, c1=4.665, c2=-34.226, g=-34.226\n",
      ">71, c1=5.006, c2=-35.117, g=-35.117\n",
      ">72, c1=5.118, c2=-35.769, g=-35.769\n",
      ">73, c1=5.028, c2=-36.446, g=-36.446\n",
      ">74, c1=5.303, c2=-37.148, g=-37.148\n",
      ">75, c1=5.330, c2=-37.915, g=-37.915\n",
      ">76, c1=5.366, c2=-38.698, g=-38.698\n",
      ">77, c1=5.380, c2=-39.412, g=-39.412\n",
      ">78, c1=5.202, c2=-40.071, g=-40.071\n",
      ">79, c1=5.132, c2=-40.704, g=-40.704\n",
      ">80, c1=5.137, c2=-41.240, g=-41.240\n",
      ">81, c1=5.128, c2=-41.735, g=-41.735\n",
      ">82, c1=5.167, c2=-42.083, g=-42.083\n",
      ">83, c1=5.388, c2=-42.463, g=-42.463\n",
      ">84, c1=5.312, c2=-42.836, g=-42.836\n",
      ">85, c1=5.315, c2=-43.305, g=-43.305\n",
      ">86, c1=5.477, c2=-43.779, g=-43.779\n",
      ">87, c1=5.382, c2=-44.270, g=-44.270\n",
      ">88, c1=5.608, c2=-44.671, g=-44.671\n",
      ">89, c1=5.739, c2=-45.020, g=-45.020\n",
      ">90, c1=5.461, c2=-45.234, g=-45.234\n",
      ">91, c1=5.333, c2=-45.454, g=-45.454\n",
      ">92, c1=5.654, c2=-45.729, g=-45.729\n",
      ">93, c1=5.892, c2=-46.020, g=-46.020\n",
      ">94, c1=5.815, c2=-46.262, g=-46.262\n",
      ">95, c1=5.288, c2=-46.222, g=-46.222\n",
      ">96, c1=5.698, c2=-46.507, g=-46.507\n",
      ">97, c1=5.623, c2=-46.876, g=-46.876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: generated_plot_0097.png and wgan_results\\model_0097.h5\n",
      ">98, c1=5.865, c2=-47.207, g=-47.207\n",
      ">99, c1=5.731, c2=-47.647, g=-47.647\n",
      ">100, c1=5.759, c2=-47.910, g=-47.910\n",
      ">101, c1=5.987, c2=-48.013, g=-48.013\n",
      ">102, c1=6.169, c2=-48.044, g=-48.044\n",
      ">103, c1=6.134, c2=-48.092, g=-48.092\n",
      ">104, c1=5.982, c2=-48.206, g=-48.206\n",
      ">105, c1=5.861, c2=-48.420, g=-48.420\n",
      ">106, c1=6.126, c2=-48.600, g=-48.600\n",
      ">107, c1=6.207, c2=-48.811, g=-48.811\n",
      ">108, c1=6.084, c2=-48.808, g=-48.808\n",
      ">109, c1=6.288, c2=-49.008, g=-49.008\n",
      ">110, c1=6.266, c2=-49.166, g=-49.166\n",
      ">111, c1=6.362, c2=-49.251, g=-49.251\n",
      ">112, c1=6.163, c2=-49.310, g=-49.310\n",
      ">113, c1=6.039, c2=-49.365, g=-49.365\n",
      ">114, c1=6.255, c2=-49.361, g=-49.361\n",
      ">115, c1=6.421, c2=-49.465, g=-49.465\n",
      ">116, c1=6.814, c2=-49.692, g=-49.692\n",
      ">117, c1=6.426, c2=-49.804, g=-49.804\n",
      ">118, c1=6.367, c2=-49.900, g=-49.900\n",
      ">119, c1=6.599, c2=-50.052, g=-50.052\n",
      ">120, c1=6.335, c2=-50.212, g=-50.212\n",
      ">121, c1=6.512, c2=-50.155, g=-50.155\n",
      ">122, c1=6.642, c2=-50.224, g=-50.224\n",
      ">123, c1=6.575, c2=-50.323, g=-50.323\n",
      ">124, c1=6.586, c2=-50.415, g=-50.415\n",
      ">125, c1=6.566, c2=-50.553, g=-50.553\n",
      ">126, c1=6.745, c2=-50.604, g=-50.604\n",
      ">127, c1=7.016, c2=-50.736, g=-50.736\n",
      ">128, c1=6.617, c2=-50.745, g=-50.745\n",
      ">129, c1=6.805, c2=-50.824, g=-50.824\n",
      ">130, c1=6.830, c2=-50.888, g=-50.888\n",
      ">131, c1=6.784, c2=-51.091, g=-51.091\n",
      ">132, c1=6.788, c2=-51.199, g=-51.199\n",
      ">133, c1=6.804, c2=-51.222, g=-51.222\n",
      ">134, c1=6.567, c2=-51.176, g=-51.176\n",
      ">135, c1=6.823, c2=-51.165, g=-51.165\n",
      ">136, c1=6.969, c2=-51.168, g=-51.168\n",
      ">137, c1=6.876, c2=-51.186, g=-51.186\n",
      ">138, c1=6.844, c2=-51.325, g=-51.325\n",
      ">139, c1=7.043, c2=-51.387, g=-51.387\n",
      ">140, c1=7.028, c2=-51.408, g=-51.408\n",
      ">141, c1=7.389, c2=-51.543, g=-51.543\n",
      ">142, c1=6.755, c2=-51.543, g=-51.543\n",
      ">143, c1=7.182, c2=-51.643, g=-51.643\n",
      ">144, c1=6.909, c2=-51.657, g=-51.657\n",
      ">145, c1=7.083, c2=-51.614, g=-51.614\n",
      ">146, c1=6.967, c2=-51.573, g=-51.573\n",
      ">147, c1=6.997, c2=-51.632, g=-51.632\n",
      ">148, c1=7.245, c2=-51.679, g=-51.679\n",
      ">149, c1=7.044, c2=-51.741, g=-51.741\n",
      ">150, c1=6.779, c2=-51.763, g=-51.763\n",
      ">151, c1=7.299, c2=-51.860, g=-51.860\n",
      ">152, c1=7.360, c2=-51.897, g=-51.897\n",
      ">153, c1=7.335, c2=-51.925, g=-51.925\n",
      ">154, c1=7.296, c2=-51.789, g=-51.789\n",
      ">155, c1=7.031, c2=-51.763, g=-51.763\n",
      ">156, c1=7.252, c2=-51.689, g=-51.689\n",
      ">157, c1=7.389, c2=-51.756, g=-51.756\n",
      ">158, c1=7.500, c2=-51.796, g=-51.796\n",
      ">159, c1=7.252, c2=-51.826, g=-51.826\n",
      ">160, c1=7.778, c2=-51.790, g=-51.790\n",
      ">161, c1=7.357, c2=-51.818, g=-51.818\n",
      ">162, c1=7.684, c2=-51.898, g=-51.898\n",
      ">163, c1=7.569, c2=-51.890, g=-51.890\n",
      ">164, c1=7.426, c2=-51.822, g=-51.822\n",
      ">165, c1=7.468, c2=-51.736, g=-51.736\n",
      ">166, c1=7.277, c2=-51.714, g=-51.714\n",
      ">167, c1=7.299, c2=-51.790, g=-51.790\n",
      ">168, c1=7.581, c2=-51.811, g=-51.811\n",
      ">169, c1=7.486, c2=-51.791, g=-51.791\n",
      ">170, c1=7.605, c2=-51.720, g=-51.720\n",
      ">171, c1=7.510, c2=-51.715, g=-51.715\n",
      ">172, c1=7.686, c2=-51.861, g=-51.861\n",
      ">173, c1=7.788, c2=-51.875, g=-51.875\n",
      ">174, c1=7.694, c2=-51.930, g=-51.930\n",
      ">175, c1=7.823, c2=-51.920, g=-51.920\n",
      ">176, c1=7.717, c2=-51.857, g=-51.857\n",
      ">177, c1=7.576, c2=-51.855, g=-51.855\n",
      ">178, c1=7.833, c2=-51.823, g=-51.823\n",
      ">179, c1=7.746, c2=-51.703, g=-51.703\n",
      ">180, c1=7.694, c2=-51.646, g=-51.646\n",
      ">181, c1=8.015, c2=-51.589, g=-51.589\n",
      ">182, c1=7.565, c2=-51.506, g=-51.506\n",
      ">183, c1=7.654, c2=-51.457, g=-51.457\n",
      ">184, c1=7.784, c2=-51.481, g=-51.481\n",
      ">185, c1=7.636, c2=-51.470, g=-51.470\n",
      ">186, c1=7.868, c2=-51.384, g=-51.384\n",
      ">187, c1=8.193, c2=-51.367, g=-51.367\n",
      ">188, c1=7.784, c2=-51.378, g=-51.378\n",
      ">189, c1=7.904, c2=-51.245, g=-51.245\n",
      ">190, c1=7.750, c2=-51.330, g=-51.330\n",
      ">191, c1=7.955, c2=-51.293, g=-51.293\n",
      ">192, c1=7.770, c2=-51.239, g=-51.239\n",
      ">193, c1=7.797, c2=-51.240, g=-51.240\n",
      ">194, c1=8.024, c2=-51.139, g=-51.139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: generated_plot_0194.png and wgan_results\\model_0194.h5\n",
      ">195, c1=8.362, c2=-51.101, g=-51.101\n",
      ">196, c1=8.192, c2=-51.072, g=-51.072\n",
      ">197, c1=8.007, c2=-50.921, g=-50.921\n",
      ">198, c1=7.848, c2=-50.908, g=-50.908\n",
      ">199, c1=7.853, c2=-51.053, g=-51.053\n",
      ">200, c1=7.928, c2=-51.043, g=-51.043\n",
      ">201, c1=8.236, c2=-50.889, g=-50.889\n",
      ">202, c1=8.186, c2=-50.720, g=-50.720\n",
      ">203, c1=8.112, c2=-50.599, g=-50.599\n",
      ">204, c1=8.092, c2=-50.447, g=-50.447\n",
      ">205, c1=8.156, c2=-50.533, g=-50.533\n",
      ">206, c1=7.939, c2=-50.422, g=-50.422\n",
      ">207, c1=8.114, c2=-50.524, g=-50.524\n",
      ">208, c1=8.218, c2=-50.413, g=-50.413\n",
      ">209, c1=8.014, c2=-50.385, g=-50.385\n",
      ">210, c1=8.261, c2=-50.363, g=-50.363\n",
      ">211, c1=8.338, c2=-50.261, g=-50.261\n",
      ">212, c1=8.240, c2=-50.092, g=-50.092\n",
      ">213, c1=8.341, c2=-49.936, g=-49.936\n",
      ">214, c1=8.627, c2=-49.831, g=-49.831\n",
      ">215, c1=8.342, c2=-49.809, g=-49.809\n",
      ">216, c1=8.241, c2=-49.766, g=-49.766\n",
      ">217, c1=8.371, c2=-49.725, g=-49.725\n",
      ">218, c1=8.481, c2=-49.602, g=-49.602\n",
      ">219, c1=8.253, c2=-49.541, g=-49.541\n",
      ">220, c1=8.708, c2=-49.477, g=-49.477\n",
      ">221, c1=8.378, c2=-49.445, g=-49.445\n",
      ">222, c1=8.381, c2=-49.387, g=-49.387\n",
      ">223, c1=8.351, c2=-49.248, g=-49.248\n",
      ">224, c1=8.288, c2=-49.119, g=-49.119\n",
      ">225, c1=8.388, c2=-48.995, g=-48.995\n",
      ">226, c1=8.788, c2=-48.903, g=-48.903\n",
      ">227, c1=8.237, c2=-48.824, g=-48.824\n",
      ">228, c1=8.286, c2=-48.670, g=-48.670\n",
      ">229, c1=8.393, c2=-48.637, g=-48.637\n",
      ">230, c1=8.505, c2=-48.599, g=-48.599\n",
      ">231, c1=8.404, c2=-48.515, g=-48.515\n",
      ">232, c1=8.428, c2=-48.336, g=-48.336\n",
      ">233, c1=8.663, c2=-48.240, g=-48.240\n",
      ">234, c1=8.545, c2=-48.241, g=-48.241\n",
      ">235, c1=8.431, c2=-48.232, g=-48.232\n",
      ">236, c1=8.620, c2=-48.176, g=-48.176\n",
      ">237, c1=8.774, c2=-48.146, g=-48.146\n",
      ">238, c1=8.629, c2=-48.013, g=-48.013\n",
      ">239, c1=8.515, c2=-47.955, g=-47.955\n",
      ">240, c1=8.535, c2=-47.849, g=-47.849\n",
      ">241, c1=8.544, c2=-47.766, g=-47.766\n",
      ">242, c1=8.769, c2=-47.494, g=-47.494\n",
      ">243, c1=8.661, c2=-47.452, g=-47.452\n",
      ">244, c1=8.987, c2=-47.264, g=-47.264\n",
      ">245, c1=8.682, c2=-47.216, g=-47.216\n",
      ">246, c1=8.688, c2=-47.105, g=-47.105\n",
      ">247, c1=8.553, c2=-46.970, g=-46.970\n",
      ">248, c1=8.662, c2=-46.868, g=-46.868\n",
      ">249, c1=8.859, c2=-46.832, g=-46.832\n",
      ">250, c1=8.700, c2=-46.694, g=-46.694\n",
      ">251, c1=8.788, c2=-46.619, g=-46.619\n",
      ">252, c1=8.661, c2=-46.488, g=-46.488\n",
      ">253, c1=8.824, c2=-46.277, g=-46.277\n",
      ">254, c1=8.431, c2=-46.164, g=-46.164\n",
      ">255, c1=8.724, c2=-46.068, g=-46.068\n",
      ">256, c1=8.865, c2=-45.881, g=-45.881\n",
      ">257, c1=8.640, c2=-45.856, g=-45.856\n",
      ">258, c1=8.574, c2=-45.646, g=-45.646\n",
      ">259, c1=8.827, c2=-45.562, g=-45.562\n",
      ">260, c1=8.729, c2=-45.487, g=-45.487\n",
      ">261, c1=8.640, c2=-45.408, g=-45.408\n",
      ">262, c1=8.781, c2=-45.316, g=-45.316\n",
      ">263, c1=8.937, c2=-45.275, g=-45.275\n",
      ">264, c1=8.761, c2=-45.119, g=-45.119\n",
      ">265, c1=8.699, c2=-44.973, g=-44.973\n",
      ">266, c1=8.767, c2=-44.810, g=-44.810\n",
      ">267, c1=8.886, c2=-44.658, g=-44.658\n",
      ">268, c1=8.895, c2=-44.611, g=-44.611\n",
      ">269, c1=8.979, c2=-44.490, g=-44.490\n",
      ">270, c1=8.955, c2=-44.410, g=-44.410\n",
      ">271, c1=8.805, c2=-44.292, g=-44.292\n",
      ">272, c1=9.200, c2=-44.173, g=-44.173\n",
      ">273, c1=9.055, c2=-44.142, g=-44.142\n",
      ">274, c1=8.687, c2=-43.889, g=-43.889\n",
      ">275, c1=9.054, c2=-43.754, g=-43.754\n",
      ">276, c1=9.081, c2=-43.571, g=-43.571\n",
      ">277, c1=8.890, c2=-43.482, g=-43.482\n",
      ">278, c1=8.964, c2=-43.429, g=-43.429\n",
      ">279, c1=9.121, c2=-43.358, g=-43.358\n",
      ">280, c1=9.001, c2=-43.244, g=-43.244\n",
      ">281, c1=9.132, c2=-43.239, g=-43.239\n",
      ">282, c1=8.934, c2=-43.099, g=-43.099\n",
      ">283, c1=8.851, c2=-42.989, g=-42.989\n",
      ">284, c1=9.342, c2=-42.936, g=-42.936\n",
      ">285, c1=8.898, c2=-42.851, g=-42.851\n",
      ">286, c1=8.951, c2=-42.735, g=-42.735\n",
      ">287, c1=8.842, c2=-42.570, g=-42.570\n",
      ">288, c1=9.245, c2=-42.540, g=-42.540\n",
      ">289, c1=8.952, c2=-42.392, g=-42.392\n",
      ">290, c1=9.135, c2=-42.309, g=-42.309\n",
      ">291, c1=9.428, c2=-42.098, g=-42.098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: generated_plot_0291.png and wgan_results\\model_0291.h5\n",
      ">292, c1=8.888, c2=-41.898, g=-41.898\n",
      ">293, c1=8.603, c2=-41.698, g=-41.698\n",
      ">294, c1=8.747, c2=-41.574, g=-41.574\n",
      ">295, c1=9.236, c2=-41.473, g=-41.473\n",
      ">296, c1=9.135, c2=-41.351, g=-41.351\n",
      ">297, c1=9.127, c2=-41.213, g=-41.213\n",
      ">298, c1=9.101, c2=-41.065, g=-41.065\n",
      ">299, c1=9.228, c2=-41.029, g=-41.029\n",
      ">300, c1=9.133, c2=-40.942, g=-40.942\n",
      ">301, c1=9.258, c2=-40.779, g=-40.779\n",
      ">302, c1=9.182, c2=-40.670, g=-40.670\n",
      ">303, c1=9.387, c2=-40.493, g=-40.493\n",
      ">304, c1=9.070, c2=-40.322, g=-40.322\n",
      ">305, c1=8.978, c2=-40.243, g=-40.243\n",
      ">306, c1=8.921, c2=-40.180, g=-40.180\n",
      ">307, c1=9.076, c2=-39.993, g=-39.993\n",
      ">308, c1=8.900, c2=-39.890, g=-39.890\n",
      ">309, c1=9.343, c2=-39.806, g=-39.806\n",
      ">310, c1=8.989, c2=-39.701, g=-39.701\n",
      ">311, c1=8.998, c2=-39.642, g=-39.642\n",
      ">312, c1=8.955, c2=-39.538, g=-39.538\n",
      ">313, c1=9.089, c2=-39.406, g=-39.406\n",
      ">314, c1=9.087, c2=-39.208, g=-39.208\n",
      ">315, c1=9.060, c2=-39.139, g=-39.139\n",
      ">316, c1=9.014, c2=-39.049, g=-39.049\n",
      ">317, c1=9.057, c2=-38.933, g=-38.933\n",
      ">318, c1=9.218, c2=-38.824, g=-38.824\n",
      ">319, c1=9.272, c2=-38.725, g=-38.725\n",
      ">320, c1=9.140, c2=-38.604, g=-38.604\n",
      ">321, c1=9.137, c2=-38.531, g=-38.531\n",
      ">322, c1=9.267, c2=-38.484, g=-38.484\n",
      ">323, c1=8.886, c2=-38.373, g=-38.373\n",
      ">324, c1=9.362, c2=-38.269, g=-38.269\n",
      ">325, c1=8.840, c2=-38.149, g=-38.149\n",
      ">326, c1=9.200, c2=-38.031, g=-38.031\n",
      ">327, c1=9.275, c2=-37.901, g=-37.901\n",
      ">328, c1=9.136, c2=-37.696, g=-37.696\n",
      ">329, c1=9.148, c2=-37.688, g=-37.688\n",
      ">330, c1=9.206, c2=-37.644, g=-37.644\n",
      ">331, c1=9.121, c2=-37.578, g=-37.578\n",
      ">332, c1=8.814, c2=-37.430, g=-37.430\n",
      ">333, c1=9.323, c2=-37.289, g=-37.289\n",
      ">334, c1=9.030, c2=-37.184, g=-37.184\n",
      ">335, c1=9.461, c2=-37.128, g=-37.128\n",
      ">336, c1=9.191, c2=-37.001, g=-37.001\n",
      ">337, c1=9.293, c2=-36.922, g=-36.922\n",
      ">338, c1=9.002, c2=-36.824, g=-36.824\n",
      ">339, c1=9.191, c2=-36.661, g=-36.661\n",
      ">340, c1=9.316, c2=-36.538, g=-36.538\n",
      ">341, c1=9.186, c2=-36.493, g=-36.493\n",
      ">342, c1=9.167, c2=-36.422, g=-36.422\n",
      ">343, c1=8.987, c2=-36.329, g=-36.329\n",
      ">344, c1=9.190, c2=-36.175, g=-36.175\n",
      ">345, c1=9.301, c2=-36.035, g=-36.035\n",
      ">346, c1=9.350, c2=-35.929, g=-35.929\n",
      ">347, c1=9.294, c2=-35.850, g=-35.850\n",
      ">348, c1=9.303, c2=-35.762, g=-35.762\n",
      ">349, c1=9.046, c2=-35.659, g=-35.659\n",
      ">350, c1=9.364, c2=-35.599, g=-35.599\n",
      ">351, c1=8.925, c2=-35.540, g=-35.540\n",
      ">352, c1=9.166, c2=-35.486, g=-35.486\n",
      ">353, c1=9.429, c2=-35.381, g=-35.381\n",
      ">354, c1=9.180, c2=-35.242, g=-35.242\n",
      ">355, c1=9.515, c2=-35.136, g=-35.136\n",
      ">356, c1=9.235, c2=-35.080, g=-35.080\n",
      ">357, c1=9.235, c2=-35.000, g=-35.000\n",
      ">358, c1=9.394, c2=-34.900, g=-34.900\n",
      ">359, c1=9.053, c2=-34.813, g=-34.813\n",
      ">360, c1=9.155, c2=-34.686, g=-34.686\n",
      ">361, c1=9.036, c2=-34.554, g=-34.554\n",
      ">362, c1=8.978, c2=-34.415, g=-34.415\n",
      ">363, c1=9.122, c2=-34.294, g=-34.294\n",
      ">364, c1=9.055, c2=-34.243, g=-34.243\n",
      ">365, c1=9.285, c2=-34.187, g=-34.187\n",
      ">366, c1=9.075, c2=-34.105, g=-34.105\n",
      ">367, c1=9.141, c2=-34.037, g=-34.037\n",
      ">368, c1=9.367, c2=-33.959, g=-33.959\n",
      ">369, c1=9.098, c2=-33.797, g=-33.797\n",
      ">370, c1=9.125, c2=-33.743, g=-33.743\n",
      ">371, c1=9.190, c2=-33.626, g=-33.626\n",
      ">372, c1=9.029, c2=-33.545, g=-33.545\n",
      ">373, c1=9.164, c2=-33.453, g=-33.453\n",
      ">374, c1=8.975, c2=-33.373, g=-33.373\n",
      ">375, c1=9.159, c2=-33.331, g=-33.331\n",
      ">376, c1=9.238, c2=-33.303, g=-33.303\n",
      ">377, c1=9.099, c2=-33.158, g=-33.158\n",
      ">378, c1=9.362, c2=-33.098, g=-33.098\n",
      ">379, c1=9.063, c2=-32.998, g=-32.998\n",
      ">380, c1=9.410, c2=-32.953, g=-32.953\n",
      ">381, c1=9.360, c2=-32.881, g=-32.881\n",
      ">382, c1=9.344, c2=-32.809, g=-32.809\n",
      ">383, c1=9.103, c2=-32.722, g=-32.722\n",
      ">384, c1=9.402, c2=-32.652, g=-32.652\n",
      ">385, c1=9.049, c2=-32.586, g=-32.586\n",
      ">386, c1=9.097, c2=-32.500, g=-32.500\n",
      ">387, c1=9.226, c2=-32.475, g=-32.475\n",
      ">388, c1=9.198, c2=-32.403, g=-32.403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: generated_plot_0388.png and wgan_results\\model_0388.h5\n",
      ">389, c1=9.194, c2=-32.332, g=-32.332\n",
      ">390, c1=9.137, c2=-32.205, g=-32.205\n",
      ">391, c1=9.006, c2=-32.078, g=-32.078\n",
      ">392, c1=9.001, c2=-31.937, g=-31.937\n",
      ">393, c1=9.164, c2=-31.853, g=-31.853\n",
      ">394, c1=9.179, c2=-31.797, g=-31.797\n",
      ">395, c1=9.122, c2=-31.712, g=-31.712\n",
      ">396, c1=9.281, c2=-31.680, g=-31.680\n",
      ">397, c1=9.076, c2=-31.543, g=-31.543\n",
      ">398, c1=9.290, c2=-31.464, g=-31.464\n",
      ">399, c1=9.216, c2=-31.412, g=-31.412\n",
      ">400, c1=9.045, c2=-31.313, g=-31.313\n",
      ">401, c1=9.156, c2=-31.262, g=-31.262\n",
      ">402, c1=9.101, c2=-31.225, g=-31.225\n",
      ">403, c1=8.927, c2=-31.195, g=-31.195\n",
      ">404, c1=9.268, c2=-31.130, g=-31.130\n",
      ">405, c1=9.244, c2=-31.059, g=-31.059\n",
      ">406, c1=9.117, c2=-30.978, g=-30.978\n",
      ">407, c1=9.225, c2=-30.889, g=-30.889\n",
      ">408, c1=9.042, c2=-30.827, g=-30.827\n",
      ">409, c1=9.442, c2=-30.788, g=-30.788\n",
      ">410, c1=9.141, c2=-30.744, g=-30.744\n",
      ">411, c1=9.226, c2=-30.643, g=-30.643\n",
      ">412, c1=9.160, c2=-30.577, g=-30.577\n",
      ">413, c1=8.947, c2=-30.510, g=-30.510\n",
      ">414, c1=8.999, c2=-30.447, g=-30.447\n",
      ">415, c1=9.562, c2=-30.378, g=-30.378\n",
      ">416, c1=8.948, c2=-30.287, g=-30.287\n",
      ">417, c1=9.038, c2=-30.213, g=-30.213\n",
      ">418, c1=9.063, c2=-30.187, g=-30.187\n",
      ">419, c1=9.405, c2=-30.154, g=-30.154\n",
      ">420, c1=9.236, c2=-30.076, g=-30.076\n",
      ">421, c1=9.236, c2=-29.984, g=-29.984\n",
      ">422, c1=8.994, c2=-29.893, g=-29.893\n",
      ">423, c1=9.118, c2=-29.821, g=-29.821\n",
      ">424, c1=9.044, c2=-29.751, g=-29.751\n",
      ">425, c1=8.766, c2=-29.697, g=-29.697\n",
      ">426, c1=9.275, c2=-29.603, g=-29.603\n",
      ">427, c1=9.370, c2=-29.579, g=-29.579\n",
      ">428, c1=9.106, c2=-29.443, g=-29.443\n",
      ">429, c1=9.035, c2=-29.358, g=-29.358\n",
      ">430, c1=8.961, c2=-29.314, g=-29.314\n",
      ">431, c1=9.079, c2=-29.299, g=-29.299\n",
      ">432, c1=9.292, c2=-29.257, g=-29.257\n",
      ">433, c1=9.197, c2=-29.219, g=-29.219\n",
      ">434, c1=9.110, c2=-29.113, g=-29.113\n",
      ">435, c1=8.956, c2=-29.081, g=-29.081\n",
      ">436, c1=9.028, c2=-28.981, g=-28.981\n",
      ">437, c1=9.099, c2=-28.910, g=-28.910\n",
      ">438, c1=9.004, c2=-28.844, g=-28.844\n",
      ">439, c1=9.115, c2=-28.802, g=-28.802\n",
      ">440, c1=9.252, c2=-28.754, g=-28.754\n",
      ">441, c1=8.975, c2=-28.765, g=-28.765\n",
      ">442, c1=8.890, c2=-28.733, g=-28.733\n",
      ">443, c1=9.211, c2=-28.686, g=-28.686\n",
      ">444, c1=9.086, c2=-28.645, g=-28.645\n",
      ">445, c1=9.266, c2=-28.609, g=-28.609\n",
      ">446, c1=9.103, c2=-28.528, g=-28.528\n",
      ">447, c1=8.995, c2=-28.446, g=-28.446\n",
      ">448, c1=9.147, c2=-28.373, g=-28.373\n",
      ">449, c1=9.030, c2=-28.323, g=-28.323\n",
      ">450, c1=8.930, c2=-28.264, g=-28.264\n",
      ">451, c1=8.953, c2=-28.232, g=-28.232\n",
      ">452, c1=9.132, c2=-28.155, g=-28.155\n",
      ">453, c1=9.034, c2=-28.088, g=-28.088\n",
      ">454, c1=8.876, c2=-28.057, g=-28.057\n",
      ">455, c1=8.998, c2=-28.080, g=-28.080\n",
      ">456, c1=9.050, c2=-28.032, g=-28.032\n",
      ">457, c1=9.016, c2=-27.954, g=-27.954\n",
      ">458, c1=9.063, c2=-27.928, g=-27.928\n",
      ">459, c1=9.039, c2=-27.868, g=-27.868\n",
      ">460, c1=8.910, c2=-27.837, g=-27.837\n",
      ">461, c1=8.859, c2=-27.779, g=-27.779\n",
      ">462, c1=9.123, c2=-27.729, g=-27.729\n",
      ">463, c1=8.935, c2=-27.679, g=-27.679\n",
      ">464, c1=8.627, c2=-27.580, g=-27.580\n",
      ">465, c1=9.104, c2=-27.531, g=-27.531\n",
      ">466, c1=9.011, c2=-27.516, g=-27.516\n",
      ">467, c1=8.874, c2=-27.433, g=-27.433\n",
      ">468, c1=8.932, c2=-27.412, g=-27.412\n",
      ">469, c1=8.863, c2=-27.360, g=-27.360\n",
      ">470, c1=8.932, c2=-27.319, g=-27.319\n",
      ">471, c1=9.009, c2=-27.264, g=-27.264\n",
      ">472, c1=8.883, c2=-27.205, g=-27.205\n",
      ">473, c1=8.866, c2=-27.134, g=-27.134\n",
      ">474, c1=8.901, c2=-27.099, g=-27.099\n",
      ">475, c1=8.924, c2=-27.091, g=-27.091\n",
      ">476, c1=9.006, c2=-27.039, g=-27.039\n",
      ">477, c1=8.961, c2=-26.976, g=-26.976\n",
      ">478, c1=8.951, c2=-26.894, g=-26.894\n",
      ">479, c1=8.772, c2=-26.854, g=-26.854\n",
      ">480, c1=9.046, c2=-26.804, g=-26.804\n",
      ">481, c1=9.136, c2=-26.791, g=-26.791\n",
      ">482, c1=8.909, c2=-26.791, g=-26.791\n",
      ">483, c1=9.135, c2=-26.779, g=-26.779\n",
      ">484, c1=8.791, c2=-26.733, g=-26.733\n",
      ">485, c1=9.054, c2=-26.683, g=-26.683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: generated_plot_0485.png and wgan_results\\model_0485.h5\n",
      ">486, c1=8.913, c2=-26.587, g=-26.587\n",
      ">487, c1=8.827, c2=-26.540, g=-26.540\n",
      ">488, c1=8.916, c2=-26.468, g=-26.468\n",
      ">489, c1=9.006, c2=-26.445, g=-26.445\n",
      ">490, c1=8.831, c2=-26.421, g=-26.421\n",
      ">491, c1=8.738, c2=-26.389, g=-26.389\n",
      ">492, c1=8.953, c2=-26.352, g=-26.352\n",
      ">493, c1=8.937, c2=-26.298, g=-26.298\n",
      ">494, c1=8.883, c2=-26.229, g=-26.229\n",
      ">495, c1=9.210, c2=-26.201, g=-26.201\n",
      ">496, c1=9.060, c2=-26.204, g=-26.204\n",
      ">497, c1=8.852, c2=-26.183, g=-26.183\n",
      ">498, c1=8.848, c2=-26.149, g=-26.149\n",
      ">499, c1=8.884, c2=-26.066, g=-26.066\n",
      ">500, c1=8.717, c2=-26.002, g=-26.002\n",
      ">501, c1=9.072, c2=-26.026, g=-26.026\n",
      ">502, c1=8.829, c2=-26.022, g=-26.022\n",
      ">503, c1=8.651, c2=-25.981, g=-25.981\n",
      ">504, c1=8.873, c2=-25.938, g=-25.938\n",
      ">505, c1=8.932, c2=-25.958, g=-25.958\n",
      ">506, c1=8.839, c2=-25.908, g=-25.908\n",
      ">507, c1=8.715, c2=-25.870, g=-25.870\n",
      ">508, c1=8.919, c2=-25.787, g=-25.787\n",
      ">509, c1=8.844, c2=-25.724, g=-25.724\n",
      ">510, c1=8.903, c2=-25.704, g=-25.704\n",
      ">511, c1=8.788, c2=-25.696, g=-25.696\n",
      ">512, c1=8.825, c2=-25.642, g=-25.642\n",
      ">513, c1=8.776, c2=-25.600, g=-25.600\n",
      ">514, c1=8.794, c2=-25.552, g=-25.552\n",
      ">515, c1=8.898, c2=-25.464, g=-25.464\n",
      ">516, c1=8.718, c2=-25.383, g=-25.383\n",
      ">517, c1=8.482, c2=-25.393, g=-25.393\n",
      ">518, c1=8.626, c2=-25.360, g=-25.360\n",
      ">519, c1=8.932, c2=-25.345, g=-25.345\n",
      ">520, c1=8.607, c2=-25.311, g=-25.311\n",
      ">521, c1=8.484, c2=-25.284, g=-25.284\n",
      ">522, c1=8.814, c2=-25.232, g=-25.232\n",
      ">523, c1=8.843, c2=-25.225, g=-25.225\n",
      ">524, c1=8.492, c2=-25.232, g=-25.232\n",
      ">525, c1=8.704, c2=-25.205, g=-25.205\n",
      ">526, c1=8.593, c2=-25.184, g=-25.184\n",
      ">527, c1=8.555, c2=-25.162, g=-25.162\n",
      ">528, c1=8.763, c2=-25.133, g=-25.133\n",
      ">529, c1=8.464, c2=-25.081, g=-25.081\n",
      ">530, c1=8.647, c2=-25.049, g=-25.049\n",
      ">531, c1=8.670, c2=-24.971, g=-24.971\n",
      ">532, c1=8.854, c2=-24.948, g=-24.948\n",
      ">533, c1=8.513, c2=-24.939, g=-24.939\n",
      ">534, c1=8.764, c2=-24.932, g=-24.932\n",
      ">535, c1=8.465, c2=-24.917, g=-24.917\n",
      ">536, c1=8.842, c2=-24.897, g=-24.897\n",
      ">537, c1=8.506, c2=-24.839, g=-24.839\n",
      ">538, c1=8.466, c2=-24.778, g=-24.778\n",
      ">539, c1=8.628, c2=-24.729, g=-24.729\n",
      ">540, c1=8.922, c2=-24.704, g=-24.704\n",
      ">541, c1=8.532, c2=-24.688, g=-24.688\n",
      ">542, c1=8.598, c2=-24.697, g=-24.697\n",
      ">543, c1=8.578, c2=-24.643, g=-24.643\n",
      ">544, c1=8.438, c2=-24.608, g=-24.608\n",
      ">545, c1=8.795, c2=-24.553, g=-24.553\n",
      ">546, c1=8.574, c2=-24.502, g=-24.502\n",
      ">547, c1=8.572, c2=-24.454, g=-24.454\n",
      ">548, c1=8.548, c2=-24.422, g=-24.422\n",
      ">549, c1=8.828, c2=-24.422, g=-24.422\n",
      ">550, c1=8.734, c2=-24.408, g=-24.408\n",
      ">551, c1=8.719, c2=-24.385, g=-24.385\n",
      ">552, c1=8.551, c2=-24.371, g=-24.371\n",
      ">553, c1=8.495, c2=-24.331, g=-24.331\n",
      ">554, c1=8.729, c2=-24.322, g=-24.322\n",
      ">555, c1=8.461, c2=-24.286, g=-24.286\n",
      ">556, c1=8.558, c2=-24.256, g=-24.256\n",
      ">557, c1=8.565, c2=-24.220, g=-24.220\n",
      ">558, c1=8.603, c2=-24.205, g=-24.205\n",
      ">559, c1=8.539, c2=-24.162, g=-24.162\n",
      ">560, c1=8.490, c2=-24.139, g=-24.139\n",
      ">561, c1=8.481, c2=-24.107, g=-24.107\n",
      ">562, c1=8.568, c2=-24.114, g=-24.114\n",
      ">563, c1=8.513, c2=-24.105, g=-24.105\n",
      ">564, c1=8.608, c2=-24.064, g=-24.064\n",
      ">565, c1=8.695, c2=-24.032, g=-24.032\n",
      ">566, c1=8.752, c2=-24.023, g=-24.023\n",
      ">567, c1=8.522, c2=-24.032, g=-24.032\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(dataset\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# train model\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcritic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgan_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatent_dim\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[56], line 14\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(g_model, c_model, gan_model, dataset, latent_dim, n_epochs, n_batch, n_critic)\u001b[0m\n\u001b[0;32m     11\u001b[0m X_real, y_real \u001b[38;5;241m=\u001b[39m generate_real_samples(dataset, n_batch \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Perform a training step\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m c1_loss, c2_loss, g_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgan_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_real\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatent_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_critic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcritic_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator_optimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Track losses\u001b[39;00m\n\u001b[0;32m     17\u001b[0m c1_hist\u001b[38;5;241m.\u001b[39mappend(c1_loss)\n",
      "File \u001b[1;32mc:\\Users\\sulai\\Documents\\GH-Projects\\GANs\\env\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\sulai\\Documents\\GH-Projects\\GANs\\env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\sulai\\Documents\\GH-Projects\\GANs\\env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:869\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    866\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    867\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    868\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 869\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    872\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    873\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    874\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    875\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\sulai\\Documents\\GH-Projects\\GANs\\env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sulai\\Documents\\GH-Projects\\GANs\\env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\sulai\\Documents\\GH-Projects\\GANs\\env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\sulai\\Documents\\GH-Projects\\GANs\\env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\sulai\\Documents\\GH-Projects\\GANs\\env\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1683\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1681\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1683\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1684\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1685\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1686\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1687\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1688\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1689\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1691\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1692\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1693\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1697\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1698\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\sulai\\Documents\\GH-Projects\\GANs\\env\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# size of the latent space\n",
    "latent_dim = 50\n",
    "# create the critic\n",
    "critic = define_critic()\n",
    "# create the generator\n",
    "generator = define_generator(latent_dim)\n",
    "# create the gan\n",
    "gan_model = define_gan(generator, critic)\n",
    "# load image data\n",
    "dataset = load_real_samples()\n",
    "print(dataset.shape)\n",
    "# train model\n",
    "train(generator, critic, gan_model, dataset, latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9a9908-1835-4858-b5b5-c52c66fb49ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bbd0cc96",
   "metadata": {},
   "source": [
    "#### References\n",
    "1. [gans-in-action](https://github.com/GANs-in-Action/gans-in-action)\n",
    "2. [Machine Learning Mastery](https://machinelearningmastery.com/how-to-code-a-wasserstein-generative-adversarial-network-wgan-from-scratch/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc66b704",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
