{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc509a10-2f26-4f29-897b-253a4b4f4957",
   "metadata": {},
   "source": [
    "# Wasserstein Generative Adversarial Network - WGAN\n",
    "---\n",
    "The Wasserstein GAN, or WGAN for short, was introduced by Martin Arjovsky, et al. in their 2017 paper titled [Wasserstein GAN](https://arxiv.org/abs/1701.07875).\n",
    "\n",
    "The Wasserstein GAN (WGAN) extends the traditional GAN by introducing an alternative approach to training the generator. Its goal is to improve the generator's ability to approximate the data distribution observed in the training dataset.\n",
    "\n",
    "Rather than using a discriminator to classify generated images as real or fake, the WGAN replaces it with a critic. The critic evaluates images by scoring their \"realness\" or \"fakeness,\" providing a continuous metric instead of binary classification.\n",
    "\n",
    "This modification is based on a theoretical principle: training the generator should minimize the distance between the data distribution in the training set and the distribution of generated samples.\n",
    "\n",
    "WGAN offers several advantages. Its training process is more stable, less sensitive to model architecture, and less dependent on hyperparameter configurations. Most importantly, the critic's loss correlates with the quality of images produced by the generator, making it a more reliable indicator of training progress."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ffe0b3",
   "metadata": {},
   "source": [
    "## Wasserstein GAN Implementation Details\n",
    "---\n",
    "Although the theoretical grounding for the WGAN is dense, the implementation of a WGAN requires a few minor changes to the standard Deep Convolutional GAN, or DCGAN.\n",
    "\n",
    "The image below provides a summary of the main training loop for training a WGAN, taken from the paper. Note the listing of recommended hyperparameters used in the model.\n",
    "\n",
    "\n",
    "![gan-algorithm](plots/wgan-algorithm.png)\n",
    "\n",
    "The differences in implementation for the WGAN are as follows:\n",
    "\n",
    "1. Use a linear activation function in the output layer of the critic model (instead of sigmoid).\n",
    "2. Use -1 labels for real images and 1 labels for fake images (instead of 1 and 0).\n",
    "3. Use Wasserstein loss to train the critic and generator models.\n",
    "4. Constrain critic model weights to a limited range after each mini batch update (e.g. [-0.01,0.01]).\n",
    "5. Update the critic model more times than the generator each iteration (e.g. 5).\n",
    "6. Use the RMSProp version of gradient descent with a small learning rate and no momentum (e.g. 0.00005).\n",
    "\n",
    "**NOTE** This code will to some extend be a modified version of that implemented in the [DCGAN](https://github.com/sulaiman-shamasna/GANs/blob/main/DCGANs.ipynb) notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a9a2c2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "da47a1bf-3d17-4242-894d-32166f722ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import expand_dims\n",
    "from numpy import mean\n",
    "from numpy import ones\n",
    "from numpy.random import randn\n",
    "from numpy.random import randint\n",
    "from keras.datasets.mnist import load_data\n",
    "from keras import backend\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.constraints import Constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "81ebcb45-ebe9-40c9-a4cc-d1e43685f3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c4727856-2270-4777-a6ca-2ae71a18cfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clip model weights to a given hypercube\n",
    "class ClipConstraint(Constraint):\n",
    "\t# set clip value when initialized\n",
    "\tdef __init__(self, clip_value):\n",
    "\t\tself.clip_value = clip_value\n",
    " \n",
    "\t# clip model weights to hypercube\n",
    "\tdef __call__(self, weights):\n",
    "\t\treturn backend.clip(weights, -self.clip_value, self.clip_value)\n",
    " \n",
    "\t# get the config\n",
    "\tdef get_config(self):\n",
    "\t\treturn {'clip_value': self.clip_value}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "27067c3f-b2f8-418d-8d9d-a0d9c81faa20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define the Wasserstein loss function\n",
    "def wasserstein_loss(y_true, y_pred):\n",
    "    return tf.reduce_mean(y_true * y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59ad77e",
   "metadata": {},
   "source": [
    "## How to Train a Wasserstein GAN Model\n",
    "---\n",
    "Now that we know the specific implementation details for the WGAN, we can implement the model for image generation.\n",
    "\n",
    "In this section, we will develop a WGAN to generate a single handwritten digit (‘7’) from the [MNIST dataset](https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-fashion-mnist-clothing-classification/). This is a good test problem for the WGAN as it is a small dataset requiring a modest mode that is quick to train.\n",
    "\n",
    "The first step is to define the models.\n",
    "\n",
    "The critic model takes as input one 28×28 grayscale image and outputs a score for the realness or fakeness of the image. It is implemented as a modest convolutional neural network using best practices for DCGAN design such as using the [LeakyReLU activation](https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/) function with a slope of 0.2, [batch normalization](https://machinelearningmastery.com/how-to-accelerate-learning-of-deep-neural-networks-with-batch-normalization/), and using a [2×2 stride to downsample](https://machinelearningmastery.com/padding-and-stride-for-convolutional-neural-networks/).\n",
    "\n",
    "The critic model makes use of the new ClipConstraint weight constraint to clip model weights after mini-batch updates and is optimized using the custom wasserstein_loss() function, the RMSProp version of stochastic gradient descent with a learning rate of 0.00005.\n",
    "\n",
    "The ```define_critic()``` function below implements this, defining and compiling the critic model and returning it. The input shape of the image is parameterized as a default function argument to make it clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "81f2e591-31ee-4e60-aad0-f92f368d193d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the standalone critic model\n",
    "def define_critic(in_shape=(28,28,1)):\n",
    "\t# weight initialization\n",
    "\tinit = RandomNormal(stddev=0.02)\n",
    "\t# weight constraint\n",
    "\tconst = ClipConstraint(0.01)\n",
    "\t# define model\n",
    "\tmodel = Sequential()\n",
    "\t# downsample to 14x14\n",
    "\tmodel.add(Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init, kernel_constraint=const, input_shape=in_shape))\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(LeakyReLU(alpha=0.2))\n",
    "\t# downsample to 7x7\n",
    "\tmodel.add(Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init, kernel_constraint=const))\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(LeakyReLU(alpha=0.2))\n",
    "\t# scoring, linear activation\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(1))\n",
    "\t# compile model\n",
    "\topt = RMSprop(learning_rate=0.00005)\n",
    "\tmodel.compile(loss=wasserstein_loss, optimizer=opt)\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "37c13c3a-b148-4215-9130-5feecb9a021d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_19\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_19\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,088</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_28          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_29          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3136</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,137</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_23 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │         \u001b[38;5;34m1,088\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_28          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_33 (\u001b[38;5;33mLeakyReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_24 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │        \u001b[38;5;34m65,600\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_29          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_34 (\u001b[38;5;33mLeakyReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_9 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3136\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │         \u001b[38;5;34m3,137\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">70,337</span> (274.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m70,337\u001b[0m (274.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">70,081</span> (273.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m70,081\u001b[0m (273.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> (1.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m256\u001b[0m (1.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "define_critic().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95dd834",
   "metadata": {},
   "source": [
    "The generator model takes as input a point in the latent space and outputs a single 28×28 grayscale image.\n",
    "\n",
    "This is achieved by using a fully connected layer to interpret the point in the latent space and provide sufficient activations that can be reshaped into many copies (in this case, 128) of a low-resolution version of the output image (e.g. 7×7). This is then upsampled two times, doubling the size and quadrupling the area of the activations each time using transpose convolutional layers.\n",
    "\n",
    "The model uses best practices such as the LeakyReLU activation, a kernel size that is a factor of the stride size, and a hyperbolic tangent (tanh) activation function in the output layer.\n",
    "\n",
    "The define_generator() function below defines the generator model but intentionally does not compile it as it is not trained directly, then returns the model. The size of the latent space is parameterized as a function argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bdbd1e44-5188-4cc0-b1ec-720596795f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the standalone generator model\n",
    "def define_generator(latent_dim):\n",
    "\t# weight initialization\n",
    "\tinit = RandomNormal(stddev=0.02)\n",
    "\t# define model\n",
    "\tmodel = Sequential()\n",
    "\t# foundation for 7x7 image\n",
    "\tn_nodes = 128 * 7 * 7\n",
    "\tmodel.add(Dense(n_nodes, kernel_initializer=init, input_dim=latent_dim))\n",
    "\tmodel.add(LeakyReLU(alpha=0.2))\n",
    "\tmodel.add(Reshape((7, 7, 128)))\n",
    "\t# upsample to 14x14\n",
    "\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init))\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(LeakyReLU(alpha=0.2))\n",
    "\t# upsample to 28x28\n",
    "\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init))\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(LeakyReLU(alpha=0.2))\n",
    "\t# output 28x28x1\n",
    "\tmodel.add(Conv2D(1, (7,7), activation='tanh', padding='same', kernel_initializer=init))\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0938dcd",
   "metadata": {},
   "source": [
    "Next, a GAN model can be defined that combines both the generator model and the critic model into one larger model.\n",
    "\n",
    "This larger model will be used to train the model weights in the generator, using the output and error calculated by the critic model. The critic model is trained separately, and as such, the model weights are marked as not trainable in this larger GAN model to ensure that only the weights of the generator model are updated. This change to the trainability of the critic weights only has an effect when training the combined GAN model, not when training the critic standalone.\n",
    "\n",
    "This larger GAN model takes as input a point in the latent space, uses the generator model to generate an image, which is fed as input to the critic model, then output scored as real or fake. The model is fit using RMSProp with the custom wasserstein_loss() function.\n",
    "\n",
    "The define_gan() function below implements this, taking the already defined generator and critic models as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "03779182-aaff-4dd9-90fd-c8b0ff472cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the combined generator and critic model, for updating the generator\n",
    "def define_gan(generator, critic):\n",
    "\t# make weights in the critic not trainable\n",
    "\tfor layer in critic.layers:\n",
    "\t\tif not isinstance(layer, BatchNormalization):\n",
    "\t\t\tlayer.trainable = False\n",
    "\t# connect them\n",
    "\tmodel = Sequential()\n",
    "\t# add generator\n",
    "\tmodel.add(generator)\n",
    "\t# add the critic\n",
    "\tmodel.add(critic)\n",
    "\t# compile model\n",
    "\topt = RMSprop(learning_rate=0.00005)\n",
    "\tmodel.compile(loss=wasserstein_loss, optimizer=opt)\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a037f3d6",
   "metadata": {},
   "source": [
    "Now that we have defined the GAN model, we need to train it. But, before we can train the model, we require input data.\n",
    "\n",
    "The first step is to load and [scale the MNIST dataset](https://machinelearningmastery.com/how-to-manually-scale-image-pixel-data-for-deep-learning/). The whole dataset is loaded via a call to the load_data() Keras function, then a subset of the images is selected (about 5,000) that belongs to class 7, e.g. are a handwritten depiction of the number seven. Then the pixel values must be scaled to the range [-1,1] to match the output of the generator model.\n",
    "\n",
    "The ```load_real_samples()``` function below implements this, returning the loaded and scaled subset of the MNIST training dataset ready for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e7e1119a-e404-4bef-a2b0-ac863b226943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images\n",
    "def load_real_samples():\n",
    "\t# load dataset\n",
    "\t(trainX, trainy), (_, _) = load_data()\n",
    "\t# select all of the examples for a given class\n",
    "\tselected_ix = trainy == 7\n",
    "\tX = trainX[selected_ix]\n",
    "\t# expand to 3d, e.g. add channels\n",
    "\tX = expand_dims(X, axis=-1)\n",
    "\t# convert from ints to floats\n",
    "\tX = X.astype('float32')\n",
    "\t# scale from [0,255] to [-1,1]\n",
    "\tX = (X - 127.5) / 127.5\n",
    "\treturn X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b46d695",
   "metadata": {},
   "source": [
    "We will require one batch (or a half) batch of real images from the dataset each update to the GAN model. A simple way to achieve this is to select a [random sample](https://machinelearningmastery.com/how-to-generate-random-numbers-in-python/) of images from the dataset each time.\n",
    "\n",
    "The ```generate_real_samples()``` function below implements this, taking the prepared dataset as an argument, selecting and returning a random sample of images and their corresponding label for the critic, specifically target=-1 indicating that they are real images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d570c6b5-7b80-44ac-a1df-c4d74f8461aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select real samples\n",
    "def generate_real_samples(dataset, n_samples):\n",
    "\t# choose random instances\n",
    "\tix = randint(0, dataset.shape[0], n_samples)\n",
    "\t# select images\n",
    "\tX = dataset[ix]\n",
    "\t# generate class labels, -1 for 'real'\n",
    "\ty = -ones((n_samples, 1))\n",
    "\treturn X, y\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9458a13",
   "metadata": {},
   "source": [
    "Next, we need inputs for the generator model. These are random points from the latent space, specifically [Gaussian distributed random variables](https://machinelearningmastery.com/how-to-generate-random-numbers-in-python/).\n",
    "\n",
    "The generate_latent_points() function implements this, taking the size of the latent space as an argument and the number of points required, and returning them as a batch of input samples for the generator model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5dc5cf4d-2c07-4d19-af24-1e734f611dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate points in latent space as input for the generator\n",
    "def generate_latent_points(latent_dim, n_samples):\n",
    "\t# generate points in the latent space\n",
    "\tx_input = randn(latent_dim * n_samples)\n",
    "\t# reshape into a batch of inputs for the network\n",
    "\tx_input = x_input.reshape(n_samples, latent_dim)\n",
    "\treturn x_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8af341c",
   "metadata": {},
   "source": [
    "Next, we need to use the points in the latent space as input to the generator in order to generate new images.\n",
    "\n",
    "The ```generate_fake_samples()``` function below implements this, taking the generator model and size of the latent space as arguments, then generating points in the latent space and using them as input to the generator model.\n",
    "\n",
    "The function returns the generated images and their corresponding label for the critic model, specifically target=1 to indicate they are fake or generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "eb2b1855-862e-43a3-ae91-2ddc3a4b16ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the generator to generate n fake examples, with class labels\n",
    "def generate_fake_samples(generator, latent_dim, n_samples):\n",
    "    # generate points in latent space\n",
    "    x_input = generate_latent_points(latent_dim, n_samples)\n",
    "    # directly call the generator\n",
    "    X = generator(x_input, training=False)\n",
    "    # create class labels with 1.0 for 'fake'\n",
    "    y = tf.ones((n_samples, 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71851c75",
   "metadata": {},
   "source": [
    "We need to record the performance of the model. Perhaps the most reliable way to evaluate the performance of a GAN is to use the generator to generate images, and then review and subjectively evaluate them.\n",
    "\n",
    "The ```summarize_performance()``` function below takes the generator model at a given point during training and uses it to generate 100 images in a 10×10 grid, that are then plotted and saved to file. The model is also saved to file at this time, in case we would like to use it later to generate more images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e60be09c-a063-4e32-a9f0-7cd054cb038d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# generate samples and save as a plot and save the model\n",
    "def summarize_performance(step, g_model, latent_dim, n_samples=100):\n",
    "\t# prepare fake examples\n",
    "\tX, _ = generate_fake_samples(g_model, latent_dim, n_samples)\n",
    "\t# scale from [-1,1] to [0,1]\n",
    "\tX = (X + 1) / 2.0\n",
    "\t# plot images\n",
    "\tfor i in range(10 * 10):\n",
    "\t\t# define subplot\n",
    "\t\tpyplot.subplot(10, 10, 1 + i)\n",
    "\t\t# turn off axis\n",
    "\t\tpyplot.axis('off')\n",
    "\t\t# plot raw pixel data\n",
    "\t\tpyplot.imshow(X[i, :, :, 0], cmap='gray_r')\n",
    "\t# save plot to file\n",
    "\tfilename1 = 'generated_plot_%04d.png' % (step+1)\n",
    "\tfilename1_dir = os.path.join('wgan_results', filename1)\t\n",
    "\tpyplot.savefig(filename1_dir)\n",
    "\tpyplot.close()\n",
    "\t# save the generator model\n",
    "\tfilename2 = 'model_%04d.h5' % (step+1)\n",
    "\tfilename2_dir = os.path.join('wgan_results', filename2)\n",
    "\tg_model.save(filename2_dir)\n",
    "\tprint('>Saved: %s and %s' % (filename1, filename2_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a330b9",
   "metadata": {},
   "source": [
    "In addition to image quality, it is a good idea to keep track of the loss and accuracy of the model over time.\n",
    "\n",
    "The loss for the critic for real and fake samples can be tracked for each model update, as can the loss for the generator for each update. These can then be used to create line plots of loss at the end of the training run. The plot_history() function below implements this and saves the results to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "91aedc74-c4df-4118-9645-f8e8b386d250",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "result_path = os.path.join('wgan_results', 'plot_line_plot_loss.png')\n",
    "# create a line plot of loss for the gan and save to file\n",
    "def plot_history(d1_hist, d2_hist, g_hist):\n",
    "\t# plot history\n",
    "\tpyplot.plot(d1_hist, label='crit_real')\n",
    "\tpyplot.plot(d2_hist, label='crit_fake')\n",
    "\tpyplot.plot(g_hist, label='gen')\n",
    "\tpyplot.legend()\n",
    "\tpyplot.savefig(result_path)\n",
    "\tpyplot.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da50da2f",
   "metadata": {},
   "source": [
    "We are now ready to fit the GAN model.\n",
    "\n",
    "The model is fit for 10 training epochs, which is arbitrary, as the model begins generating plausible number-7 digits after perhaps the first few epochs. A batch size of 64 samples is used, and each training epoch involves 6,265/64, or about 97, batches of real and fake samples and updates to the model. The model is therefore trained for 10 epochs of 97 batches, or 970 iterations.\n",
    "\n",
    "First, the critic model is updated for a half batch of real samples, then a half batch of fake samples, together forming one batch of weight updates. This is then repeated n_critic (5) times as required by the WGAN algorithm.\n",
    "\n",
    "The generator is then updated via the composite GAN model. Importantly, the target label is set to -1 or real for the generated samples. This has the effect of updating the generator toward getting better at generating real samples on the next batch.\n",
    "\n",
    "The train() function below implements this, taking the defined models, dataset, and size of the latent dimension as arguments and parameterizing the number of epochs and batch size with default arguments. The generator model is saved at the end of training.\n",
    "\n",
    "The performance of the critic and generator models is reported each iteration. Sample images are generated and saved every epoch, and line plots of model performance are created and saved at the end of the run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3cefe3e3-3345-4890-83df-4e7a89f6b35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimizers outside of the train_step function\n",
    "critic_optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.00005)\n",
    "generator_optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.00005)\n",
    "\n",
    "@tf.function\n",
    "def train_step(g_model, c_model, gan_model, real_images, latent_dim, n_batch, n_critic, critic_optimizer, generator_optimizer):\n",
    "    c1_losses, c2_losses = [], []\n",
    "\n",
    "    # Train the critic more frequently than the generator\n",
    "    for _ in range(n_critic):\n",
    "        # Generate fake images\n",
    "        fake_images, y_fake = generate_fake_samples(g_model, latent_dim, n_batch // 2)\n",
    "        y_real = -tf.ones((n_batch // 2, 1))  # Label for real images in WGAN\n",
    "\n",
    "        # Update critic on real images\n",
    "        with tf.GradientTape() as c_tape:\n",
    "            real_output = c_model(real_images, training=True)\n",
    "            fake_output = c_model(fake_images, training=True)\n",
    "            c_loss = tf.reduce_mean(fake_output) - tf.reduce_mean(real_output)\n",
    "\n",
    "        # Apply gradients to critic\n",
    "        c_gradients = c_tape.gradient(c_loss, c_model.trainable_variables)\n",
    "        critic_optimizer.apply_gradients(zip(c_gradients, c_model.trainable_variables))\n",
    "        c1_losses.append(c_loss)\n",
    "\n",
    "    # Prepare latent points and inverted labels for generator update\n",
    "    latent_points = generate_latent_points(latent_dim, n_batch)\n",
    "    y_gan = -tf.ones((n_batch, 1))\n",
    "\n",
    "    # Update generator via critic’s loss\n",
    "    with tf.GradientTape() as g_tape:\n",
    "        generated_images = g_model(latent_points, training=True)\n",
    "        fake_output = c_model(generated_images, training=False)\n",
    "        g_loss = -tf.reduce_mean(fake_output)\n",
    "\n",
    "    # Apply gradients to generator\n",
    "    g_gradients = g_tape.gradient(g_loss, g_model.trainable_variables)\n",
    "    generator_optimizer.apply_gradients(zip(g_gradients, g_model.trainable_variables))\n",
    "    c2_losses.append(g_loss)\n",
    "\n",
    "    return tf.reduce_mean(c1_losses), tf.reduce_mean(c2_losses), g_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "317a26ef-25e3-4df4-9ae9-efd39a8f1090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the generator and critic\n",
    "def train(g_model, c_model, gan_model, dataset, latent_dim, n_epochs=10, n_batch=64, n_critic=5):\n",
    "    bat_per_epo = int(dataset.shape[0] / n_batch)\n",
    "    n_steps = bat_per_epo * n_epochs\n",
    "    \n",
    "    # Lists for keeping track of loss\n",
    "    c1_hist, c2_hist, g_hist = list(), list(), list()\n",
    "    \n",
    "    for i in range(n_steps):\n",
    "        # Get randomly selected 'real' samples\n",
    "        X_real, y_real = generate_real_samples(dataset, n_batch // 2)\n",
    "        \n",
    "        # Perform a training step\n",
    "        c1_loss, c2_loss, g_loss = train_step(g_model, c_model, gan_model, X_real, latent_dim, n_batch, n_critic, critic_optimizer, generator_optimizer)\n",
    "        \n",
    "        # Track losses\n",
    "        c1_hist.append(c1_loss)\n",
    "        c2_hist.append(c2_loss)\n",
    "        g_hist.append(g_loss)\n",
    "        \n",
    "        print(f'>{i+1}, c1={c1_loss:.3f}, c2={c2_loss:.3f}, g={g_loss:.3f}')\n",
    "        \n",
    "        # Summarize performance\n",
    "        if (i+1) % bat_per_epo == 0:\n",
    "            summarize_performance(i, g_model, latent_dim)\n",
    "    \n",
    "    plot_history(c1_hist, c2_hist, g_hist)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afeb133a",
   "metadata": {},
   "source": [
    "Now that all of the functions have been defined, we can create the models, load the dataset, and begin the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5f5384ae-41a2-4a70-ac81-c02656da63df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6265, 28, 28, 1)\n",
      ">1, c1=0.132, c2=-0.020, g=-0.020\n",
      ">2, c1=0.273, c2=-0.065, g=-0.065\n",
      ">3, c1=0.428, c2=-0.108, g=-0.108\n",
      ">4, c1=0.431, c2=-0.149, g=-0.149\n",
      ">5, c1=0.529, c2=-0.193, g=-0.193\n",
      ">6, c1=0.539, c2=-0.239, g=-0.239\n",
      ">7, c1=0.420, c2=-0.290, g=-0.290\n",
      ">8, c1=1.075, c2=-0.348, g=-0.348\n",
      ">9, c1=0.826, c2=-0.409, g=-0.409\n",
      ">10, c1=0.897, c2=-0.473, g=-0.473\n",
      ">11, c1=0.943, c2=-0.542, g=-0.542\n",
      ">12, c1=1.009, c2=-0.630, g=-0.630\n",
      ">13, c1=1.003, c2=-0.719, g=-0.719\n",
      ">14, c1=1.291, c2=-0.816, g=-0.816\n",
      ">15, c1=1.356, c2=-0.914, g=-0.914\n",
      ">16, c1=1.201, c2=-1.043, g=-1.043\n",
      ">17, c1=1.414, c2=-1.182, g=-1.182\n",
      ">18, c1=1.386, c2=-1.333, g=-1.333\n",
      ">19, c1=1.382, c2=-1.501, g=-1.501\n",
      ">20, c1=1.527, c2=-1.672, g=-1.672\n",
      ">21, c1=1.478, c2=-1.872, g=-1.872\n",
      ">22, c1=1.658, c2=-2.079, g=-2.079\n",
      ">23, c1=1.610, c2=-2.319, g=-2.319\n",
      ">24, c1=1.729, c2=-2.567, g=-2.567\n",
      ">25, c1=1.612, c2=-2.824, g=-2.824\n",
      ">26, c1=1.888, c2=-3.094, g=-3.094\n",
      ">27, c1=1.983, c2=-3.430, g=-3.430\n",
      ">28, c1=1.809, c2=-3.791, g=-3.791\n",
      ">29, c1=2.164, c2=-4.179, g=-4.179\n",
      ">30, c1=1.953, c2=-4.590, g=-4.590\n",
      ">31, c1=2.013, c2=-5.019, g=-5.019\n",
      ">32, c1=2.241, c2=-5.493, g=-5.493\n",
      ">33, c1=2.065, c2=-5.981, g=-5.981\n",
      ">34, c1=1.978, c2=-6.517, g=-6.517\n",
      ">35, c1=2.196, c2=-7.053, g=-7.053\n",
      ">36, c1=2.184, c2=-7.606, g=-7.606\n",
      ">37, c1=2.260, c2=-8.160, g=-8.160\n",
      ">38, c1=2.523, c2=-8.824, g=-8.824\n",
      ">39, c1=2.375, c2=-9.525, g=-9.525\n",
      ">40, c1=2.353, c2=-10.256, g=-10.256\n",
      ">41, c1=2.298, c2=-11.016, g=-11.016\n",
      ">42, c1=2.514, c2=-11.809, g=-11.809\n",
      ">43, c1=2.458, c2=-12.643, g=-12.643\n",
      ">44, c1=2.318, c2=-13.475, g=-13.475\n",
      ">45, c1=2.506, c2=-14.340, g=-14.340\n",
      ">46, c1=2.790, c2=-15.218, g=-15.218\n",
      ">47, c1=2.774, c2=-16.182, g=-16.182\n",
      ">48, c1=2.753, c2=-17.176, g=-17.176\n",
      ">49, c1=2.860, c2=-18.198, g=-18.198\n",
      ">50, c1=3.324, c2=-19.206, g=-19.206\n",
      ">51, c1=2.905, c2=-20.237, g=-20.237\n",
      ">52, c1=2.693, c2=-21.238, g=-21.238\n",
      ">53, c1=3.092, c2=-22.193, g=-22.193\n",
      ">54, c1=3.206, c2=-23.201, g=-23.201\n",
      ">55, c1=2.966, c2=-24.343, g=-24.343\n",
      ">56, c1=3.032, c2=-25.528, g=-25.528\n",
      ">57, c1=2.942, c2=-26.666, g=-26.666\n",
      ">58, c1=3.225, c2=-27.802, g=-27.802\n",
      ">59, c1=3.310, c2=-28.935, g=-28.935\n",
      ">60, c1=3.192, c2=-30.028, g=-30.028\n",
      ">61, c1=3.295, c2=-31.085, g=-31.085\n",
      ">62, c1=3.197, c2=-32.168, g=-32.168\n",
      ">63, c1=3.153, c2=-33.091, g=-33.091\n",
      ">64, c1=3.437, c2=-34.022, g=-34.022\n",
      ">65, c1=3.533, c2=-35.006, g=-35.006\n",
      ">66, c1=3.592, c2=-36.067, g=-36.067\n",
      ">67, c1=3.293, c2=-37.020, g=-37.020\n",
      ">68, c1=3.559, c2=-38.024, g=-38.024\n",
      ">69, c1=3.536, c2=-39.027, g=-39.027\n",
      ">70, c1=3.459, c2=-39.850, g=-39.850\n",
      ">71, c1=3.652, c2=-40.630, g=-40.630\n",
      ">72, c1=3.677, c2=-41.273, g=-41.273\n",
      ">73, c1=3.444, c2=-41.826, g=-41.826\n",
      ">74, c1=3.597, c2=-42.566, g=-42.566\n",
      ">75, c1=4.038, c2=-43.404, g=-43.404\n",
      ">76, c1=3.769, c2=-44.206, g=-44.206\n",
      ">77, c1=3.916, c2=-45.020, g=-45.020\n",
      ">78, c1=4.130, c2=-45.666, g=-45.666\n",
      ">79, c1=4.098, c2=-46.154, g=-46.154\n",
      ">80, c1=4.013, c2=-46.716, g=-46.716\n",
      ">81, c1=4.125, c2=-47.255, g=-47.255\n",
      ">82, c1=3.908, c2=-47.782, g=-47.782\n",
      ">83, c1=4.090, c2=-48.335, g=-48.335\n",
      ">84, c1=4.238, c2=-48.604, g=-48.604\n",
      ">85, c1=4.119, c2=-48.969, g=-48.969\n",
      ">86, c1=4.428, c2=-49.251, g=-49.251\n",
      ">87, c1=4.109, c2=-49.590, g=-49.590\n",
      ">88, c1=4.438, c2=-50.039, g=-50.039\n",
      ">89, c1=4.176, c2=-50.473, g=-50.473\n",
      ">90, c1=4.487, c2=-50.805, g=-50.805\n",
      ">91, c1=4.716, c2=-51.117, g=-51.117\n",
      ">92, c1=4.302, c2=-51.365, g=-51.365\n",
      ">93, c1=4.401, c2=-51.776, g=-51.776\n",
      ">94, c1=4.488, c2=-51.968, g=-51.968\n",
      ">95, c1=4.638, c2=-52.336, g=-52.336\n",
      ">96, c1=4.613, c2=-52.559, g=-52.559\n",
      ">97, c1=4.681, c2=-52.870, g=-52.870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: generated_plot_0097.png and wgan_results\\model_0097.h5\n",
      ">98, c1=4.841, c2=-53.072, g=-53.072\n",
      ">99, c1=4.665, c2=-53.298, g=-53.298\n",
      ">100, c1=4.788, c2=-53.570, g=-53.570\n",
      ">101, c1=4.514, c2=-53.818, g=-53.818\n",
      ">102, c1=4.604, c2=-53.976, g=-53.976\n",
      ">103, c1=4.631, c2=-53.996, g=-53.996\n",
      ">104, c1=5.161, c2=-54.203, g=-54.203\n",
      ">105, c1=5.033, c2=-54.352, g=-54.352\n",
      ">106, c1=4.962, c2=-54.528, g=-54.528\n",
      ">107, c1=5.104, c2=-54.678, g=-54.678\n",
      ">108, c1=5.000, c2=-54.710, g=-54.710\n",
      ">109, c1=4.786, c2=-54.800, g=-54.800\n",
      ">110, c1=5.147, c2=-54.906, g=-54.906\n",
      ">111, c1=4.995, c2=-54.998, g=-54.998\n",
      ">112, c1=5.325, c2=-55.214, g=-55.214\n",
      ">113, c1=5.302, c2=-55.383, g=-55.383\n",
      ">114, c1=5.159, c2=-55.529, g=-55.529\n",
      ">115, c1=5.327, c2=-55.750, g=-55.750\n",
      ">116, c1=5.307, c2=-55.889, g=-55.889\n",
      ">117, c1=5.250, c2=-55.983, g=-55.983\n",
      ">118, c1=5.500, c2=-55.889, g=-55.889\n",
      ">119, c1=5.385, c2=-56.135, g=-56.135\n",
      ">120, c1=5.046, c2=-56.214, g=-56.214\n",
      ">121, c1=5.338, c2=-56.287, g=-56.287\n",
      ">122, c1=5.270, c2=-56.359, g=-56.359\n",
      ">123, c1=5.590, c2=-56.398, g=-56.398\n",
      ">124, c1=5.451, c2=-56.524, g=-56.524\n",
      ">125, c1=5.587, c2=-56.710, g=-56.710\n",
      ">126, c1=5.327, c2=-56.932, g=-56.932\n",
      ">127, c1=5.353, c2=-57.145, g=-57.145\n",
      ">128, c1=5.929, c2=-57.214, g=-57.214\n",
      ">129, c1=5.722, c2=-57.287, g=-57.287\n",
      ">130, c1=5.863, c2=-57.261, g=-57.261\n",
      ">131, c1=5.930, c2=-57.372, g=-57.372\n",
      ">132, c1=5.524, c2=-57.371, g=-57.371\n",
      ">133, c1=5.922, c2=-57.384, g=-57.384\n",
      ">134, c1=5.742, c2=-57.323, g=-57.323\n",
      ">135, c1=6.058, c2=-57.454, g=-57.454\n",
      ">136, c1=5.801, c2=-57.545, g=-57.545\n",
      ">137, c1=5.995, c2=-57.573, g=-57.573\n",
      ">138, c1=6.148, c2=-57.608, g=-57.608\n",
      ">139, c1=6.084, c2=-57.614, g=-57.614\n",
      ">140, c1=6.052, c2=-57.669, g=-57.669\n",
      ">141, c1=6.054, c2=-57.720, g=-57.720\n",
      ">142, c1=6.083, c2=-57.813, g=-57.813\n",
      ">143, c1=5.909, c2=-57.669, g=-57.669\n",
      ">144, c1=6.095, c2=-57.720, g=-57.720\n",
      ">145, c1=6.122, c2=-57.775, g=-57.775\n",
      ">146, c1=6.106, c2=-57.821, g=-57.821\n",
      ">147, c1=6.183, c2=-57.868, g=-57.868\n",
      ">148, c1=6.201, c2=-57.859, g=-57.859\n",
      ">149, c1=6.305, c2=-57.776, g=-57.776\n",
      ">150, c1=6.560, c2=-57.682, g=-57.682\n",
      ">151, c1=6.101, c2=-57.663, g=-57.663\n",
      ">152, c1=6.258, c2=-57.843, g=-57.843\n",
      ">153, c1=6.274, c2=-57.860, g=-57.860\n",
      ">154, c1=6.156, c2=-57.973, g=-57.973\n",
      ">155, c1=6.498, c2=-57.890, g=-57.890\n",
      ">156, c1=6.313, c2=-58.015, g=-58.015\n",
      ">157, c1=6.253, c2=-57.880, g=-57.880\n",
      ">158, c1=6.466, c2=-57.956, g=-57.956\n",
      ">159, c1=6.285, c2=-57.945, g=-57.945\n",
      ">160, c1=6.632, c2=-57.929, g=-57.929\n",
      ">161, c1=6.665, c2=-57.972, g=-57.972\n",
      ">162, c1=6.460, c2=-58.000, g=-58.000\n",
      ">163, c1=6.602, c2=-57.972, g=-57.972\n",
      ">164, c1=6.565, c2=-57.794, g=-57.794\n",
      ">165, c1=6.908, c2=-57.710, g=-57.710\n",
      ">166, c1=6.576, c2=-57.707, g=-57.707\n",
      ">167, c1=6.703, c2=-57.643, g=-57.643\n",
      ">168, c1=6.748, c2=-57.611, g=-57.611\n",
      ">169, c1=6.743, c2=-57.605, g=-57.605\n",
      ">170, c1=6.711, c2=-57.711, g=-57.711\n",
      ">171, c1=6.714, c2=-57.746, g=-57.746\n",
      ">172, c1=6.821, c2=-57.869, g=-57.869\n",
      ">173, c1=6.737, c2=-57.706, g=-57.706\n",
      ">174, c1=7.022, c2=-57.530, g=-57.530\n",
      ">175, c1=6.887, c2=-57.502, g=-57.502\n",
      ">176, c1=6.969, c2=-57.591, g=-57.591\n",
      ">177, c1=6.868, c2=-57.602, g=-57.602\n",
      ">178, c1=6.911, c2=-57.525, g=-57.525\n",
      ">179, c1=6.997, c2=-57.484, g=-57.484\n",
      ">180, c1=7.023, c2=-57.586, g=-57.586\n",
      ">181, c1=6.947, c2=-57.481, g=-57.481\n",
      ">182, c1=6.981, c2=-57.294, g=-57.294\n",
      ">183, c1=7.095, c2=-57.209, g=-57.209\n",
      ">184, c1=7.116, c2=-57.175, g=-57.175\n",
      ">185, c1=7.142, c2=-57.040, g=-57.040\n",
      ">186, c1=7.331, c2=-56.971, g=-56.971\n",
      ">187, c1=6.905, c2=-57.047, g=-57.047\n",
      ">188, c1=7.396, c2=-57.041, g=-57.041\n",
      ">189, c1=7.268, c2=-56.927, g=-56.927\n",
      ">190, c1=7.044, c2=-57.053, g=-57.053\n",
      ">191, c1=7.402, c2=-56.972, g=-56.972\n",
      ">192, c1=7.252, c2=-56.903, g=-56.903\n",
      ">193, c1=7.333, c2=-56.706, g=-56.706\n",
      ">194, c1=7.331, c2=-56.585, g=-56.585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: generated_plot_0194.png and wgan_results\\model_0194.h5\n",
      ">195, c1=7.428, c2=-56.485, g=-56.485\n",
      ">196, c1=7.311, c2=-56.452, g=-56.452\n",
      ">197, c1=7.358, c2=-56.412, g=-56.412\n",
      ">198, c1=7.362, c2=-56.244, g=-56.244\n",
      ">199, c1=7.608, c2=-56.211, g=-56.211\n",
      ">200, c1=7.395, c2=-56.082, g=-56.082\n",
      ">201, c1=7.337, c2=-56.052, g=-56.052\n",
      ">202, c1=7.842, c2=-55.988, g=-55.988\n",
      ">203, c1=7.442, c2=-55.987, g=-55.987\n",
      ">204, c1=7.586, c2=-55.849, g=-55.849\n",
      ">205, c1=7.537, c2=-55.731, g=-55.731\n",
      ">206, c1=7.618, c2=-55.699, g=-55.699\n",
      ">207, c1=7.645, c2=-55.657, g=-55.657\n",
      ">208, c1=7.261, c2=-55.690, g=-55.690\n",
      ">209, c1=7.737, c2=-55.840, g=-55.840\n",
      ">210, c1=7.745, c2=-55.799, g=-55.799\n",
      ">211, c1=7.926, c2=-55.748, g=-55.748\n",
      ">212, c1=7.787, c2=-55.515, g=-55.515\n",
      ">213, c1=7.570, c2=-55.356, g=-55.356\n",
      ">214, c1=7.621, c2=-55.285, g=-55.285\n",
      ">215, c1=7.590, c2=-55.274, g=-55.274\n",
      ">216, c1=7.784, c2=-55.114, g=-55.114\n",
      ">217, c1=8.005, c2=-55.026, g=-55.026\n",
      ">218, c1=7.962, c2=-54.877, g=-54.877\n",
      ">219, c1=7.470, c2=-54.817, g=-54.817\n",
      ">220, c1=7.717, c2=-54.639, g=-54.639\n",
      ">221, c1=7.770, c2=-54.526, g=-54.526\n",
      ">222, c1=7.725, c2=-54.459, g=-54.459\n",
      ">223, c1=7.923, c2=-54.407, g=-54.407\n",
      ">224, c1=7.853, c2=-54.322, g=-54.322\n",
      ">225, c1=7.898, c2=-54.203, g=-54.203\n",
      ">226, c1=7.922, c2=-54.096, g=-54.096\n",
      ">227, c1=7.707, c2=-53.904, g=-53.904\n",
      ">228, c1=8.018, c2=-53.777, g=-53.777\n",
      ">229, c1=8.188, c2=-53.755, g=-53.755\n",
      ">230, c1=8.093, c2=-53.670, g=-53.670\n",
      ">231, c1=8.405, c2=-53.556, g=-53.556\n",
      ">232, c1=8.220, c2=-53.471, g=-53.471\n",
      ">233, c1=7.920, c2=-53.441, g=-53.441\n",
      ">234, c1=8.039, c2=-53.349, g=-53.349\n",
      ">235, c1=8.086, c2=-53.253, g=-53.253\n",
      ">236, c1=8.212, c2=-53.112, g=-53.112\n",
      ">237, c1=8.122, c2=-52.957, g=-52.957\n",
      ">238, c1=8.435, c2=-52.751, g=-52.751\n",
      ">239, c1=8.123, c2=-52.580, g=-52.580\n",
      ">240, c1=8.237, c2=-52.454, g=-52.454\n",
      ">241, c1=8.300, c2=-52.351, g=-52.351\n",
      ">242, c1=8.398, c2=-52.257, g=-52.257\n",
      ">243, c1=8.193, c2=-52.194, g=-52.194\n",
      ">244, c1=8.288, c2=-52.063, g=-52.063\n",
      ">245, c1=8.387, c2=-51.951, g=-51.951\n",
      ">246, c1=8.263, c2=-51.833, g=-51.833\n",
      ">247, c1=8.242, c2=-51.754, g=-51.754\n",
      ">248, c1=8.358, c2=-51.732, g=-51.732\n",
      ">249, c1=8.481, c2=-51.575, g=-51.575\n",
      ">250, c1=8.561, c2=-51.467, g=-51.467\n",
      ">251, c1=8.419, c2=-51.356, g=-51.356\n",
      ">252, c1=8.536, c2=-51.160, g=-51.160\n",
      ">253, c1=8.406, c2=-51.073, g=-51.073\n",
      ">254, c1=8.373, c2=-50.971, g=-50.971\n",
      ">255, c1=8.312, c2=-50.909, g=-50.909\n",
      ">256, c1=8.757, c2=-50.816, g=-50.816\n",
      ">257, c1=8.583, c2=-50.756, g=-50.756\n",
      ">258, c1=8.573, c2=-50.606, g=-50.606\n",
      ">259, c1=8.469, c2=-50.253, g=-50.253\n",
      ">260, c1=8.527, c2=-50.003, g=-50.003\n",
      ">261, c1=8.579, c2=-49.993, g=-49.993\n",
      ">262, c1=8.320, c2=-49.896, g=-49.896\n",
      ">263, c1=8.477, c2=-49.838, g=-49.838\n",
      ">264, c1=8.671, c2=-49.735, g=-49.735\n",
      ">265, c1=8.450, c2=-49.586, g=-49.586\n",
      ">266, c1=8.636, c2=-49.402, g=-49.402\n",
      ">267, c1=8.670, c2=-49.335, g=-49.335\n",
      ">268, c1=8.618, c2=-49.170, g=-49.170\n",
      ">269, c1=8.613, c2=-49.047, g=-49.047\n",
      ">270, c1=8.574, c2=-48.864, g=-48.864\n",
      ">271, c1=8.626, c2=-48.779, g=-48.779\n",
      ">272, c1=8.498, c2=-48.714, g=-48.714\n",
      ">273, c1=8.583, c2=-48.606, g=-48.606\n",
      ">274, c1=8.656, c2=-48.426, g=-48.426\n",
      ">275, c1=8.898, c2=-48.308, g=-48.308\n",
      ">276, c1=8.763, c2=-48.314, g=-48.314\n",
      ">277, c1=8.632, c2=-48.213, g=-48.213\n",
      ">278, c1=8.950, c2=-48.094, g=-48.094\n",
      ">279, c1=8.854, c2=-48.077, g=-48.077\n",
      ">280, c1=8.957, c2=-47.981, g=-47.981\n",
      ">281, c1=8.948, c2=-47.816, g=-47.816\n",
      ">282, c1=9.023, c2=-47.624, g=-47.624\n",
      ">283, c1=8.655, c2=-47.572, g=-47.572\n",
      ">284, c1=9.013, c2=-47.463, g=-47.463\n",
      ">285, c1=8.922, c2=-47.358, g=-47.358\n",
      ">286, c1=8.601, c2=-47.439, g=-47.439\n",
      ">287, c1=9.100, c2=-47.270, g=-47.270\n",
      ">288, c1=8.971, c2=-47.071, g=-47.071\n",
      ">289, c1=8.987, c2=-46.920, g=-46.920\n",
      ">290, c1=8.906, c2=-46.711, g=-46.711\n",
      ">291, c1=8.822, c2=-46.405, g=-46.405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: generated_plot_0291.png and wgan_results\\model_0291.h5\n",
      ">292, c1=9.031, c2=-46.236, g=-46.236\n",
      ">293, c1=8.922, c2=-46.096, g=-46.096\n",
      ">294, c1=8.924, c2=-46.021, g=-46.021\n",
      ">295, c1=8.941, c2=-45.850, g=-45.850\n",
      ">296, c1=9.058, c2=-45.718, g=-45.718\n",
      ">297, c1=8.873, c2=-45.613, g=-45.613\n",
      ">298, c1=9.160, c2=-45.422, g=-45.422\n",
      ">299, c1=9.004, c2=-45.266, g=-45.266\n",
      ">300, c1=8.925, c2=-45.196, g=-45.196\n",
      ">301, c1=9.085, c2=-45.219, g=-45.219\n",
      ">302, c1=9.175, c2=-45.047, g=-45.047\n",
      ">303, c1=9.012, c2=-45.034, g=-45.034\n",
      ">304, c1=8.863, c2=-44.978, g=-44.978\n",
      ">305, c1=8.951, c2=-44.888, g=-44.888\n",
      ">306, c1=9.153, c2=-44.689, g=-44.689\n",
      ">307, c1=9.199, c2=-44.501, g=-44.501\n",
      ">308, c1=9.277, c2=-44.501, g=-44.501\n",
      ">309, c1=9.064, c2=-44.409, g=-44.409\n",
      ">310, c1=9.205, c2=-44.266, g=-44.266\n",
      ">311, c1=9.200, c2=-44.031, g=-44.031\n",
      ">312, c1=9.127, c2=-43.872, g=-43.872\n",
      ">313, c1=8.967, c2=-43.770, g=-43.770\n",
      ">314, c1=9.006, c2=-43.659, g=-43.659\n",
      ">315, c1=9.261, c2=-43.586, g=-43.586\n",
      ">316, c1=9.216, c2=-43.490, g=-43.490\n",
      ">317, c1=9.323, c2=-43.451, g=-43.451\n",
      ">318, c1=9.146, c2=-43.415, g=-43.415\n",
      ">319, c1=9.101, c2=-43.314, g=-43.314\n",
      ">320, c1=9.283, c2=-43.168, g=-43.168\n",
      ">321, c1=9.237, c2=-43.063, g=-43.063\n",
      ">322, c1=9.136, c2=-42.957, g=-42.957\n",
      ">323, c1=9.101, c2=-42.785, g=-42.785\n",
      ">324, c1=8.979, c2=-42.649, g=-42.649\n",
      ">325, c1=9.327, c2=-42.466, g=-42.466\n",
      ">326, c1=9.342, c2=-42.311, g=-42.311\n",
      ">327, c1=9.299, c2=-42.185, g=-42.185\n",
      ">328, c1=9.262, c2=-42.134, g=-42.134\n",
      ">329, c1=9.272, c2=-42.035, g=-42.035\n",
      ">330, c1=9.142, c2=-41.904, g=-41.904\n",
      ">331, c1=9.194, c2=-41.880, g=-41.880\n",
      ">332, c1=9.058, c2=-41.781, g=-41.781\n",
      ">333, c1=9.026, c2=-41.638, g=-41.638\n",
      ">334, c1=9.011, c2=-41.523, g=-41.523\n",
      ">335, c1=9.197, c2=-41.299, g=-41.299\n",
      ">336, c1=8.998, c2=-41.306, g=-41.306\n",
      ">337, c1=9.432, c2=-41.232, g=-41.232\n",
      ">338, c1=9.097, c2=-41.174, g=-41.174\n",
      ">339, c1=9.225, c2=-41.017, g=-41.017\n",
      ">340, c1=9.364, c2=-40.925, g=-40.925\n",
      ">341, c1=9.365, c2=-40.797, g=-40.797\n",
      ">342, c1=9.550, c2=-40.599, g=-40.599\n",
      ">343, c1=9.437, c2=-40.406, g=-40.406\n",
      ">344, c1=9.026, c2=-40.254, g=-40.254\n",
      ">345, c1=9.246, c2=-40.198, g=-40.198\n",
      ">346, c1=9.327, c2=-40.037, g=-40.037\n",
      ">347, c1=9.481, c2=-39.876, g=-39.876\n",
      ">348, c1=9.268, c2=-39.840, g=-39.840\n",
      ">349, c1=9.194, c2=-39.706, g=-39.706\n",
      ">350, c1=9.625, c2=-39.507, g=-39.507\n",
      ">351, c1=9.373, c2=-39.425, g=-39.425\n",
      ">352, c1=9.363, c2=-39.352, g=-39.352\n",
      ">353, c1=9.341, c2=-39.201, g=-39.201\n",
      ">354, c1=9.407, c2=-39.100, g=-39.100\n",
      ">355, c1=9.465, c2=-39.004, g=-39.004\n",
      ">356, c1=9.372, c2=-38.951, g=-38.951\n",
      ">357, c1=9.383, c2=-38.742, g=-38.742\n",
      ">358, c1=9.430, c2=-38.589, g=-38.589\n",
      ">359, c1=9.278, c2=-38.562, g=-38.562\n",
      ">360, c1=9.540, c2=-38.524, g=-38.524\n",
      ">361, c1=9.446, c2=-38.463, g=-38.463\n",
      ">362, c1=9.490, c2=-38.343, g=-38.343\n",
      ">363, c1=9.736, c2=-38.316, g=-38.316\n",
      ">364, c1=9.404, c2=-38.205, g=-38.205\n",
      ">365, c1=9.608, c2=-38.174, g=-38.174\n",
      ">366, c1=9.301, c2=-38.050, g=-38.050\n",
      ">367, c1=9.428, c2=-37.939, g=-37.939\n",
      ">368, c1=9.370, c2=-37.881, g=-37.881\n",
      ">369, c1=9.503, c2=-37.766, g=-37.766\n",
      ">370, c1=9.628, c2=-37.686, g=-37.686\n",
      ">371, c1=9.563, c2=-37.622, g=-37.622\n",
      ">372, c1=9.464, c2=-37.560, g=-37.560\n",
      ">373, c1=9.482, c2=-37.513, g=-37.513\n",
      ">374, c1=9.580, c2=-37.402, g=-37.402\n",
      ">375, c1=9.571, c2=-37.151, g=-37.151\n",
      ">376, c1=9.196, c2=-37.118, g=-37.118\n",
      ">377, c1=9.651, c2=-37.124, g=-37.124\n",
      ">378, c1=9.212, c2=-37.045, g=-37.045\n",
      ">379, c1=9.512, c2=-37.011, g=-37.011\n",
      ">380, c1=9.610, c2=-36.887, g=-36.887\n",
      ">381, c1=9.370, c2=-36.789, g=-36.789\n",
      ">382, c1=9.138, c2=-36.647, g=-36.647\n",
      ">383, c1=9.505, c2=-36.477, g=-36.477\n",
      ">384, c1=9.438, c2=-36.369, g=-36.369\n",
      ">385, c1=9.834, c2=-36.326, g=-36.326\n",
      ">386, c1=9.577, c2=-36.322, g=-36.322\n",
      ">387, c1=9.476, c2=-36.260, g=-36.260\n",
      ">388, c1=9.591, c2=-36.084, g=-36.084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: generated_plot_0388.png and wgan_results\\model_0388.h5\n",
      ">389, c1=9.162, c2=-35.990, g=-35.990\n",
      ">390, c1=9.626, c2=-35.932, g=-35.932\n",
      ">391, c1=9.320, c2=-35.861, g=-35.861\n",
      ">392, c1=9.422, c2=-35.832, g=-35.832\n",
      ">393, c1=9.567, c2=-35.731, g=-35.731\n",
      ">394, c1=9.370, c2=-35.591, g=-35.591\n",
      ">395, c1=9.507, c2=-35.453, g=-35.453\n",
      ">396, c1=9.547, c2=-35.316, g=-35.316\n",
      ">397, c1=9.482, c2=-35.186, g=-35.186\n",
      ">398, c1=9.276, c2=-35.119, g=-35.119\n",
      ">399, c1=9.460, c2=-35.044, g=-35.044\n",
      ">400, c1=9.641, c2=-34.989, g=-34.989\n",
      ">401, c1=9.569, c2=-34.868, g=-34.868\n",
      ">402, c1=9.688, c2=-34.788, g=-34.788\n",
      ">403, c1=9.462, c2=-34.717, g=-34.717\n",
      ">404, c1=9.675, c2=-34.646, g=-34.646\n",
      ">405, c1=9.296, c2=-34.583, g=-34.583\n",
      ">406, c1=9.533, c2=-34.523, g=-34.523\n",
      ">407, c1=9.415, c2=-34.473, g=-34.473\n",
      ">408, c1=9.547, c2=-34.392, g=-34.392\n",
      ">409, c1=9.427, c2=-34.303, g=-34.303\n",
      ">410, c1=9.417, c2=-34.171, g=-34.171\n",
      ">411, c1=9.493, c2=-34.142, g=-34.142\n",
      ">412, c1=9.524, c2=-34.146, g=-34.146\n",
      ">413, c1=9.597, c2=-34.074, g=-34.074\n",
      ">414, c1=9.532, c2=-33.897, g=-33.897\n",
      ">415, c1=9.644, c2=-33.827, g=-33.827\n",
      ">416, c1=9.699, c2=-33.777, g=-33.777\n",
      ">417, c1=9.797, c2=-33.713, g=-33.713\n",
      ">418, c1=9.290, c2=-33.677, g=-33.677\n",
      ">419, c1=9.513, c2=-33.535, g=-33.535\n",
      ">420, c1=9.482, c2=-33.466, g=-33.466\n",
      ">421, c1=9.567, c2=-33.388, g=-33.388\n",
      ">422, c1=9.511, c2=-33.321, g=-33.321\n",
      ">423, c1=9.414, c2=-33.242, g=-33.242\n",
      ">424, c1=9.570, c2=-33.137, g=-33.137\n",
      ">425, c1=9.379, c2=-33.057, g=-33.057\n",
      ">426, c1=9.526, c2=-33.044, g=-33.044\n",
      ">427, c1=9.509, c2=-33.000, g=-33.000\n",
      ">428, c1=9.488, c2=-32.962, g=-32.962\n",
      ">429, c1=9.626, c2=-32.920, g=-32.920\n",
      ">430, c1=9.529, c2=-32.877, g=-32.877\n",
      ">431, c1=9.476, c2=-32.774, g=-32.774\n",
      ">432, c1=9.311, c2=-32.721, g=-32.721\n",
      ">433, c1=9.599, c2=-32.609, g=-32.609\n",
      ">434, c1=9.462, c2=-32.513, g=-32.513\n",
      ">435, c1=9.770, c2=-32.460, g=-32.460\n",
      ">436, c1=9.668, c2=-32.443, g=-32.443\n",
      ">437, c1=9.607, c2=-32.434, g=-32.434\n",
      ">438, c1=9.461, c2=-32.381, g=-32.381\n",
      ">439, c1=9.422, c2=-32.289, g=-32.289\n",
      ">440, c1=9.686, c2=-32.200, g=-32.200\n",
      ">441, c1=9.545, c2=-32.133, g=-32.133\n",
      ">442, c1=9.518, c2=-32.129, g=-32.129\n",
      ">443, c1=9.452, c2=-32.046, g=-32.046\n",
      ">444, c1=9.826, c2=-31.969, g=-31.969\n",
      ">445, c1=9.591, c2=-31.895, g=-31.895\n",
      ">446, c1=9.631, c2=-31.850, g=-31.850\n",
      ">447, c1=9.532, c2=-31.792, g=-31.792\n",
      ">448, c1=9.464, c2=-31.692, g=-31.692\n",
      ">449, c1=9.399, c2=-31.560, g=-31.560\n",
      ">450, c1=9.575, c2=-31.487, g=-31.487\n",
      ">451, c1=9.658, c2=-31.473, g=-31.473\n",
      ">452, c1=9.495, c2=-31.458, g=-31.458\n",
      ">453, c1=9.546, c2=-31.338, g=-31.338\n",
      ">454, c1=9.650, c2=-31.279, g=-31.279\n",
      ">455, c1=9.649, c2=-31.245, g=-31.245\n",
      ">456, c1=9.751, c2=-31.192, g=-31.192\n",
      ">457, c1=9.381, c2=-31.072, g=-31.072\n",
      ">458, c1=9.500, c2=-31.028, g=-31.028\n",
      ">459, c1=9.568, c2=-30.959, g=-30.959\n",
      ">460, c1=9.680, c2=-30.931, g=-30.931\n",
      ">461, c1=9.602, c2=-30.923, g=-30.923\n",
      ">462, c1=9.511, c2=-30.884, g=-30.884\n",
      ">463, c1=9.514, c2=-30.870, g=-30.870\n",
      ">464, c1=9.402, c2=-30.779, g=-30.779\n",
      ">465, c1=9.603, c2=-30.724, g=-30.724\n",
      ">466, c1=9.620, c2=-30.673, g=-30.673\n",
      ">467, c1=9.516, c2=-30.624, g=-30.624\n",
      ">468, c1=9.450, c2=-30.628, g=-30.628\n",
      ">469, c1=9.433, c2=-30.505, g=-30.505\n",
      ">470, c1=9.479, c2=-30.436, g=-30.436\n",
      ">471, c1=9.580, c2=-30.427, g=-30.427\n",
      ">472, c1=9.539, c2=-30.396, g=-30.396\n",
      ">473, c1=9.438, c2=-30.340, g=-30.340\n",
      ">474, c1=9.428, c2=-30.266, g=-30.266\n",
      ">475, c1=9.477, c2=-30.198, g=-30.198\n",
      ">476, c1=9.511, c2=-30.158, g=-30.158\n",
      ">477, c1=9.673, c2=-30.155, g=-30.155\n",
      ">478, c1=9.459, c2=-30.079, g=-30.079\n",
      ">479, c1=9.637, c2=-30.014, g=-30.014\n",
      ">480, c1=9.662, c2=-29.954, g=-29.954\n",
      ">481, c1=9.661, c2=-29.888, g=-29.888\n",
      ">482, c1=9.305, c2=-29.848, g=-29.848\n",
      ">483, c1=9.358, c2=-29.814, g=-29.814\n",
      ">484, c1=9.381, c2=-29.792, g=-29.792\n",
      ">485, c1=9.375, c2=-29.752, g=-29.752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: generated_plot_0485.png and wgan_results\\model_0485.h5\n",
      ">486, c1=9.517, c2=-29.708, g=-29.708\n",
      ">487, c1=9.433, c2=-29.674, g=-29.674\n",
      ">488, c1=9.457, c2=-29.602, g=-29.602\n",
      ">489, c1=9.514, c2=-29.539, g=-29.539\n",
      ">490, c1=9.346, c2=-29.454, g=-29.454\n",
      ">491, c1=9.627, c2=-29.361, g=-29.361\n",
      ">492, c1=9.613, c2=-29.284, g=-29.284\n",
      ">493, c1=9.470, c2=-29.253, g=-29.253\n",
      ">494, c1=9.208, c2=-29.258, g=-29.258\n",
      ">495, c1=9.420, c2=-29.270, g=-29.270\n",
      ">496, c1=9.571, c2=-29.248, g=-29.248\n",
      ">497, c1=9.211, c2=-29.261, g=-29.261\n",
      ">498, c1=9.494, c2=-29.233, g=-29.233\n",
      ">499, c1=9.464, c2=-29.129, g=-29.129\n",
      ">500, c1=9.519, c2=-29.104, g=-29.104\n",
      ">501, c1=9.379, c2=-29.033, g=-29.033\n",
      ">502, c1=9.376, c2=-28.998, g=-28.998\n",
      ">503, c1=9.359, c2=-28.953, g=-28.953\n",
      ">504, c1=9.237, c2=-28.909, g=-28.909\n",
      ">505, c1=9.504, c2=-28.872, g=-28.872\n",
      ">506, c1=9.678, c2=-28.835, g=-28.835\n",
      ">507, c1=9.412, c2=-28.785, g=-28.785\n",
      ">508, c1=9.318, c2=-28.718, g=-28.718\n",
      ">509, c1=9.446, c2=-28.732, g=-28.732\n",
      ">510, c1=9.327, c2=-28.703, g=-28.703\n",
      ">511, c1=9.276, c2=-28.678, g=-28.678\n",
      ">512, c1=9.375, c2=-28.635, g=-28.635\n",
      ">513, c1=9.441, c2=-28.654, g=-28.654\n",
      ">514, c1=9.308, c2=-28.559, g=-28.559\n",
      ">515, c1=9.436, c2=-28.516, g=-28.516\n",
      ">516, c1=9.538, c2=-28.505, g=-28.505\n",
      ">517, c1=9.297, c2=-28.489, g=-28.489\n",
      ">518, c1=9.250, c2=-28.411, g=-28.411\n",
      ">519, c1=9.480, c2=-28.340, g=-28.340\n",
      ">520, c1=9.323, c2=-28.252, g=-28.252\n",
      ">521, c1=9.492, c2=-28.227, g=-28.227\n",
      ">522, c1=9.351, c2=-28.165, g=-28.165\n",
      ">523, c1=9.216, c2=-28.187, g=-28.187\n",
      ">524, c1=9.492, c2=-28.211, g=-28.211\n",
      ">525, c1=9.344, c2=-28.172, g=-28.172\n",
      ">526, c1=9.444, c2=-28.164, g=-28.164\n",
      ">527, c1=9.375, c2=-28.105, g=-28.105\n",
      ">528, c1=9.198, c2=-28.041, g=-28.041\n",
      ">529, c1=9.477, c2=-27.969, g=-27.969\n",
      ">530, c1=9.538, c2=-27.911, g=-27.911\n",
      ">531, c1=9.268, c2=-27.882, g=-27.882\n",
      ">532, c1=9.315, c2=-27.857, g=-27.857\n",
      ">533, c1=9.326, c2=-27.823, g=-27.823\n",
      ">534, c1=9.605, c2=-27.776, g=-27.776\n",
      ">535, c1=9.420, c2=-27.725, g=-27.725\n",
      ">536, c1=9.295, c2=-27.650, g=-27.650\n",
      ">537, c1=9.508, c2=-27.599, g=-27.599\n",
      ">538, c1=9.278, c2=-27.543, g=-27.543\n",
      ">539, c1=9.281, c2=-27.518, g=-27.518\n",
      ">540, c1=9.264, c2=-27.493, g=-27.493\n",
      ">541, c1=9.208, c2=-27.494, g=-27.494\n",
      ">542, c1=9.255, c2=-27.495, g=-27.495\n",
      ">543, c1=9.454, c2=-27.460, g=-27.460\n",
      ">544, c1=9.358, c2=-27.408, g=-27.408\n",
      ">545, c1=9.043, c2=-27.415, g=-27.415\n",
      ">546, c1=8.995, c2=-27.406, g=-27.406\n",
      ">547, c1=9.161, c2=-27.379, g=-27.379\n",
      ">548, c1=9.362, c2=-27.351, g=-27.351\n",
      ">549, c1=9.413, c2=-27.357, g=-27.357\n",
      ">550, c1=9.347, c2=-27.305, g=-27.305\n",
      ">551, c1=9.187, c2=-27.278, g=-27.278\n",
      ">552, c1=9.389, c2=-27.204, g=-27.204\n",
      ">553, c1=9.013, c2=-27.141, g=-27.141\n",
      ">554, c1=9.195, c2=-27.063, g=-27.063\n",
      ">555, c1=9.152, c2=-27.070, g=-27.070\n",
      ">556, c1=9.347, c2=-27.077, g=-27.077\n",
      ">557, c1=9.419, c2=-27.074, g=-27.074\n",
      ">558, c1=9.234, c2=-27.047, g=-27.047\n",
      ">559, c1=9.079, c2=-27.014, g=-27.014\n",
      ">560, c1=9.088, c2=-26.980, g=-26.980\n",
      ">561, c1=9.375, c2=-26.896, g=-26.896\n",
      ">562, c1=9.064, c2=-26.865, g=-26.865\n",
      ">563, c1=9.379, c2=-26.811, g=-26.811\n",
      ">564, c1=9.348, c2=-26.769, g=-26.769\n",
      ">565, c1=9.196, c2=-26.761, g=-26.761\n",
      ">566, c1=9.190, c2=-26.718, g=-26.718\n",
      ">567, c1=9.407, c2=-26.690, g=-26.690\n",
      ">568, c1=9.216, c2=-26.672, g=-26.672\n",
      ">569, c1=9.203, c2=-26.602, g=-26.602\n",
      ">570, c1=9.098, c2=-26.566, g=-26.566\n",
      ">571, c1=9.361, c2=-26.530, g=-26.530\n",
      ">572, c1=9.333, c2=-26.517, g=-26.517\n",
      ">573, c1=9.242, c2=-26.495, g=-26.495\n",
      ">574, c1=8.942, c2=-26.485, g=-26.485\n",
      ">575, c1=9.063, c2=-26.515, g=-26.515\n",
      ">576, c1=9.289, c2=-26.474, g=-26.474\n",
      ">577, c1=9.258, c2=-26.494, g=-26.494\n",
      ">578, c1=9.174, c2=-26.465, g=-26.465\n",
      ">579, c1=9.255, c2=-26.505, g=-26.505\n",
      ">580, c1=9.160, c2=-26.438, g=-26.438\n",
      ">581, c1=9.136, c2=-26.402, g=-26.402\n",
      ">582, c1=9.151, c2=-26.417, g=-26.417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: generated_plot_0582.png and wgan_results\\model_0582.h5\n",
      ">583, c1=9.266, c2=-26.394, g=-26.394\n",
      ">584, c1=9.136, c2=-26.409, g=-26.409\n",
      ">585, c1=9.110, c2=-26.411, g=-26.411\n",
      ">586, c1=9.030, c2=-26.358, g=-26.358\n",
      ">587, c1=9.181, c2=-26.286, g=-26.286\n",
      ">588, c1=9.020, c2=-26.269, g=-26.269\n",
      ">589, c1=9.095, c2=-26.270, g=-26.270\n",
      ">590, c1=9.065, c2=-26.211, g=-26.211\n",
      ">591, c1=9.120, c2=-26.170, g=-26.170\n",
      ">592, c1=9.244, c2=-26.123, g=-26.123\n",
      ">593, c1=9.124, c2=-26.115, g=-26.115\n",
      ">594, c1=8.940, c2=-26.066, g=-26.066\n",
      ">595, c1=9.129, c2=-26.003, g=-26.003\n",
      ">596, c1=9.004, c2=-25.995, g=-25.995\n",
      ">597, c1=9.032, c2=-25.967, g=-25.967\n",
      ">598, c1=9.270, c2=-25.939, g=-25.939\n",
      ">599, c1=8.949, c2=-25.935, g=-25.935\n",
      ">600, c1=9.134, c2=-25.872, g=-25.872\n",
      ">601, c1=8.944, c2=-25.868, g=-25.868\n",
      ">602, c1=8.837, c2=-25.866, g=-25.866\n",
      ">603, c1=9.102, c2=-25.839, g=-25.839\n",
      ">604, c1=9.163, c2=-25.783, g=-25.783\n",
      ">605, c1=8.966, c2=-25.775, g=-25.775\n",
      ">606, c1=8.882, c2=-25.757, g=-25.757\n",
      ">607, c1=9.044, c2=-25.695, g=-25.695\n",
      ">608, c1=9.204, c2=-25.645, g=-25.645\n",
      ">609, c1=8.794, c2=-25.611, g=-25.611\n",
      ">610, c1=8.983, c2=-25.625, g=-25.625\n",
      ">611, c1=9.137, c2=-25.599, g=-25.599\n",
      ">612, c1=9.086, c2=-25.553, g=-25.553\n",
      ">613, c1=8.815, c2=-25.506, g=-25.506\n",
      ">614, c1=8.805, c2=-25.536, g=-25.536\n",
      ">615, c1=9.118, c2=-25.515, g=-25.515\n",
      ">616, c1=8.976, c2=-25.509, g=-25.509\n",
      ">617, c1=9.187, c2=-25.497, g=-25.497\n",
      ">618, c1=9.018, c2=-25.475, g=-25.475\n",
      ">619, c1=9.186, c2=-25.471, g=-25.471\n",
      ">620, c1=8.849, c2=-25.450, g=-25.450\n",
      ">621, c1=8.972, c2=-25.467, g=-25.467\n",
      ">622, c1=8.945, c2=-25.413, g=-25.413\n",
      ">623, c1=9.152, c2=-25.357, g=-25.357\n",
      ">624, c1=8.866, c2=-25.356, g=-25.356\n",
      ">625, c1=8.707, c2=-25.285, g=-25.285\n",
      ">626, c1=9.076, c2=-25.283, g=-25.283\n",
      ">627, c1=8.953, c2=-25.239, g=-25.239\n",
      ">628, c1=8.773, c2=-25.230, g=-25.230\n",
      ">629, c1=8.726, c2=-25.198, g=-25.198\n",
      ">630, c1=8.850, c2=-25.155, g=-25.155\n",
      ">631, c1=8.926, c2=-25.153, g=-25.153\n",
      ">632, c1=8.765, c2=-25.130, g=-25.130\n",
      ">633, c1=8.962, c2=-25.119, g=-25.119\n",
      ">634, c1=8.857, c2=-25.090, g=-25.090\n",
      ">635, c1=8.884, c2=-25.083, g=-25.083\n",
      ">636, c1=8.991, c2=-25.048, g=-25.048\n",
      ">637, c1=8.787, c2=-25.040, g=-25.040\n",
      ">638, c1=8.962, c2=-25.020, g=-25.020\n",
      ">639, c1=8.890, c2=-25.026, g=-25.026\n",
      ">640, c1=8.901, c2=-24.967, g=-24.967\n",
      ">641, c1=8.736, c2=-24.969, g=-24.969\n",
      ">642, c1=8.912, c2=-24.965, g=-24.965\n",
      ">643, c1=8.721, c2=-24.962, g=-24.962\n",
      ">644, c1=8.684, c2=-24.943, g=-24.943\n",
      ">645, c1=8.860, c2=-24.892, g=-24.892\n",
      ">646, c1=8.848, c2=-24.871, g=-24.871\n",
      ">647, c1=8.895, c2=-24.847, g=-24.847\n",
      ">648, c1=8.908, c2=-24.806, g=-24.806\n",
      ">649, c1=8.544, c2=-24.805, g=-24.805\n",
      ">650, c1=8.737, c2=-24.829, g=-24.829\n",
      ">651, c1=8.957, c2=-24.817, g=-24.817\n",
      ">652, c1=8.641, c2=-24.803, g=-24.803\n",
      ">653, c1=8.571, c2=-24.775, g=-24.775\n",
      ">654, c1=8.814, c2=-24.729, g=-24.729\n",
      ">655, c1=8.875, c2=-24.670, g=-24.670\n",
      ">656, c1=8.764, c2=-24.651, g=-24.651\n",
      ">657, c1=8.740, c2=-24.659, g=-24.659\n",
      ">658, c1=8.660, c2=-24.697, g=-24.697\n",
      ">659, c1=8.710, c2=-24.677, g=-24.677\n",
      ">660, c1=8.672, c2=-24.624, g=-24.624\n",
      ">661, c1=8.703, c2=-24.597, g=-24.597\n",
      ">662, c1=8.817, c2=-24.574, g=-24.574\n",
      ">663, c1=8.815, c2=-24.591, g=-24.591\n",
      ">664, c1=8.595, c2=-24.543, g=-24.543\n",
      ">665, c1=8.741, c2=-24.566, g=-24.566\n",
      ">666, c1=8.806, c2=-24.579, g=-24.579\n",
      ">667, c1=8.733, c2=-24.578, g=-24.578\n",
      ">668, c1=8.700, c2=-24.520, g=-24.520\n",
      ">669, c1=8.758, c2=-24.466, g=-24.466\n",
      ">670, c1=8.584, c2=-24.446, g=-24.446\n",
      ">671, c1=8.821, c2=-24.466, g=-24.466\n",
      ">672, c1=8.833, c2=-24.421, g=-24.421\n",
      ">673, c1=8.589, c2=-24.418, g=-24.418\n",
      ">674, c1=8.564, c2=-24.409, g=-24.409\n",
      ">675, c1=8.604, c2=-24.411, g=-24.411\n",
      ">676, c1=8.751, c2=-24.391, g=-24.391\n",
      ">677, c1=8.652, c2=-24.342, g=-24.342\n",
      ">678, c1=8.634, c2=-24.357, g=-24.357\n",
      ">679, c1=8.584, c2=-24.337, g=-24.337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: generated_plot_0679.png and wgan_results\\model_0679.h5\n",
      ">680, c1=8.805, c2=-24.317, g=-24.317\n",
      ">681, c1=8.497, c2=-24.282, g=-24.282\n",
      ">682, c1=8.603, c2=-24.285, g=-24.285\n",
      ">683, c1=8.366, c2=-24.278, g=-24.278\n",
      ">684, c1=8.716, c2=-24.231, g=-24.231\n",
      ">685, c1=8.751, c2=-24.229, g=-24.229\n",
      ">686, c1=8.577, c2=-24.199, g=-24.199\n",
      ">687, c1=8.452, c2=-24.194, g=-24.194\n",
      ">688, c1=8.616, c2=-24.187, g=-24.187\n",
      ">689, c1=8.524, c2=-24.160, g=-24.160\n",
      ">690, c1=8.582, c2=-24.107, g=-24.107\n",
      ">691, c1=8.466, c2=-24.115, g=-24.115\n",
      ">692, c1=8.627, c2=-24.120, g=-24.120\n",
      ">693, c1=8.465, c2=-24.104, g=-24.104\n",
      ">694, c1=8.424, c2=-24.113, g=-24.113\n",
      ">695, c1=8.526, c2=-24.084, g=-24.084\n",
      ">696, c1=8.745, c2=-24.066, g=-24.066\n",
      ">697, c1=8.600, c2=-24.069, g=-24.069\n",
      ">698, c1=8.494, c2=-24.077, g=-24.077\n",
      ">699, c1=8.282, c2=-24.068, g=-24.068\n",
      ">700, c1=8.507, c2=-24.047, g=-24.047\n",
      ">701, c1=8.496, c2=-23.995, g=-23.995\n",
      ">702, c1=8.497, c2=-23.973, g=-23.973\n",
      ">703, c1=8.468, c2=-23.981, g=-23.981\n",
      ">704, c1=8.378, c2=-23.970, g=-23.970\n",
      ">705, c1=8.504, c2=-23.954, g=-23.954\n",
      ">706, c1=8.430, c2=-23.923, g=-23.923\n",
      ">707, c1=8.517, c2=-23.881, g=-23.881\n",
      ">708, c1=8.649, c2=-23.909, g=-23.909\n",
      ">709, c1=8.438, c2=-23.863, g=-23.863\n",
      ">710, c1=8.356, c2=-23.858, g=-23.858\n",
      ">711, c1=8.511, c2=-23.827, g=-23.827\n",
      ">712, c1=8.467, c2=-23.794, g=-23.794\n",
      ">713, c1=8.487, c2=-23.749, g=-23.749\n",
      ">714, c1=8.360, c2=-23.720, g=-23.720\n",
      ">715, c1=8.327, c2=-23.754, g=-23.754\n",
      ">716, c1=8.359, c2=-23.782, g=-23.782\n",
      ">717, c1=8.624, c2=-23.760, g=-23.760\n",
      ">718, c1=8.515, c2=-23.739, g=-23.739\n",
      ">719, c1=8.212, c2=-23.735, g=-23.735\n",
      ">720, c1=8.352, c2=-23.697, g=-23.697\n",
      ">721, c1=8.511, c2=-23.680, g=-23.680\n",
      ">722, c1=8.281, c2=-23.680, g=-23.680\n",
      ">723, c1=8.541, c2=-23.670, g=-23.670\n",
      ">724, c1=8.368, c2=-23.650, g=-23.650\n",
      ">725, c1=8.543, c2=-23.640, g=-23.640\n",
      ">726, c1=8.411, c2=-23.644, g=-23.644\n",
      ">727, c1=8.384, c2=-23.634, g=-23.634\n",
      ">728, c1=8.322, c2=-23.606, g=-23.606\n",
      ">729, c1=8.348, c2=-23.598, g=-23.598\n",
      ">730, c1=8.206, c2=-23.578, g=-23.578\n",
      ">731, c1=8.392, c2=-23.563, g=-23.563\n",
      ">732, c1=8.300, c2=-23.544, g=-23.544\n",
      ">733, c1=8.408, c2=-23.524, g=-23.524\n",
      ">734, c1=8.358, c2=-23.506, g=-23.506\n",
      ">735, c1=8.278, c2=-23.517, g=-23.517\n",
      ">736, c1=8.370, c2=-23.529, g=-23.529\n",
      ">737, c1=8.390, c2=-23.473, g=-23.473\n",
      ">738, c1=8.554, c2=-23.436, g=-23.436\n",
      ">739, c1=8.315, c2=-23.377, g=-23.377\n",
      ">740, c1=8.197, c2=-23.398, g=-23.398\n",
      ">741, c1=8.349, c2=-23.348, g=-23.348\n",
      ">742, c1=8.097, c2=-23.331, g=-23.331\n",
      ">743, c1=8.110, c2=-23.332, g=-23.332\n",
      ">744, c1=8.205, c2=-23.336, g=-23.336\n",
      ">745, c1=8.081, c2=-23.317, g=-23.317\n",
      ">746, c1=8.022, c2=-23.325, g=-23.325\n",
      ">747, c1=8.462, c2=-23.330, g=-23.330\n",
      ">748, c1=8.263, c2=-23.335, g=-23.335\n",
      ">749, c1=8.356, c2=-23.281, g=-23.281\n",
      ">750, c1=8.316, c2=-23.277, g=-23.277\n",
      ">751, c1=8.156, c2=-23.285, g=-23.285\n",
      ">752, c1=8.465, c2=-23.275, g=-23.275\n",
      ">753, c1=7.983, c2=-23.248, g=-23.248\n",
      ">754, c1=8.191, c2=-23.214, g=-23.214\n",
      ">755, c1=8.314, c2=-23.209, g=-23.209\n",
      ">756, c1=8.209, c2=-23.231, g=-23.231\n",
      ">757, c1=8.175, c2=-23.211, g=-23.211\n",
      ">758, c1=7.923, c2=-23.256, g=-23.256\n",
      ">759, c1=8.310, c2=-23.233, g=-23.233\n",
      ">760, c1=8.127, c2=-23.202, g=-23.202\n",
      ">761, c1=8.407, c2=-23.166, g=-23.166\n",
      ">762, c1=8.220, c2=-23.142, g=-23.142\n",
      ">763, c1=8.192, c2=-23.135, g=-23.135\n",
      ">764, c1=8.171, c2=-23.136, g=-23.136\n",
      ">765, c1=8.275, c2=-23.114, g=-23.114\n",
      ">766, c1=8.128, c2=-23.118, g=-23.118\n",
      ">767, c1=8.232, c2=-23.138, g=-23.138\n",
      ">768, c1=8.161, c2=-23.125, g=-23.125\n",
      ">769, c1=8.147, c2=-23.094, g=-23.094\n",
      ">770, c1=8.082, c2=-23.068, g=-23.068\n",
      ">771, c1=8.271, c2=-23.055, g=-23.055\n",
      ">772, c1=8.246, c2=-23.047, g=-23.047\n",
      ">773, c1=8.218, c2=-23.016, g=-23.016\n",
      ">774, c1=8.122, c2=-22.996, g=-22.996\n",
      ">775, c1=8.222, c2=-22.935, g=-22.935\n",
      ">776, c1=7.972, c2=-22.923, g=-22.923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: generated_plot_0776.png and wgan_results\\model_0776.h5\n",
      ">777, c1=8.363, c2=-22.931, g=-22.931\n",
      ">778, c1=8.127, c2=-22.935, g=-22.935\n",
      ">779, c1=7.951, c2=-22.889, g=-22.889\n",
      ">780, c1=8.079, c2=-22.897, g=-22.897\n",
      ">781, c1=7.934, c2=-22.893, g=-22.893\n",
      ">782, c1=8.241, c2=-22.859, g=-22.859\n",
      ">783, c1=8.074, c2=-22.822, g=-22.822\n",
      ">784, c1=8.016, c2=-22.761, g=-22.761\n",
      ">785, c1=8.227, c2=-22.731, g=-22.731\n",
      ">786, c1=7.885, c2=-22.718, g=-22.718\n",
      ">787, c1=8.055, c2=-22.691, g=-22.691\n",
      ">788, c1=7.992, c2=-22.679, g=-22.679\n",
      ">789, c1=8.006, c2=-22.688, g=-22.688\n",
      ">790, c1=8.217, c2=-22.688, g=-22.688\n",
      ">791, c1=8.439, c2=-22.693, g=-22.693\n",
      ">792, c1=7.979, c2=-22.675, g=-22.675\n",
      ">793, c1=8.000, c2=-22.682, g=-22.682\n",
      ">794, c1=7.958, c2=-22.692, g=-22.692\n",
      ">795, c1=8.124, c2=-22.656, g=-22.656\n",
      ">796, c1=8.116, c2=-22.645, g=-22.645\n",
      ">797, c1=8.015, c2=-22.626, g=-22.626\n",
      ">798, c1=8.035, c2=-22.631, g=-22.631\n",
      ">799, c1=8.072, c2=-22.616, g=-22.616\n",
      ">800, c1=7.909, c2=-22.627, g=-22.627\n",
      ">801, c1=8.102, c2=-22.626, g=-22.626\n",
      ">802, c1=7.990, c2=-22.612, g=-22.612\n",
      ">803, c1=7.951, c2=-22.607, g=-22.607\n",
      ">804, c1=8.010, c2=-22.553, g=-22.553\n",
      ">805, c1=8.010, c2=-22.519, g=-22.519\n",
      ">806, c1=7.805, c2=-22.538, g=-22.538\n",
      ">807, c1=7.955, c2=-22.548, g=-22.548\n",
      ">808, c1=7.937, c2=-22.538, g=-22.538\n",
      ">809, c1=8.048, c2=-22.544, g=-22.544\n",
      ">810, c1=7.831, c2=-22.514, g=-22.514\n",
      ">811, c1=7.977, c2=-22.484, g=-22.484\n",
      ">812, c1=7.724, c2=-22.453, g=-22.453\n",
      ">813, c1=7.986, c2=-22.439, g=-22.439\n",
      ">814, c1=7.907, c2=-22.437, g=-22.437\n",
      ">815, c1=7.886, c2=-22.394, g=-22.394\n",
      ">816, c1=7.957, c2=-22.379, g=-22.379\n",
      ">817, c1=7.981, c2=-22.375, g=-22.375\n",
      ">818, c1=7.855, c2=-22.406, g=-22.406\n",
      ">819, c1=7.989, c2=-22.431, g=-22.431\n",
      ">820, c1=7.964, c2=-22.429, g=-22.429\n",
      ">821, c1=7.770, c2=-22.402, g=-22.402\n",
      ">822, c1=7.709, c2=-22.389, g=-22.389\n",
      ">823, c1=7.837, c2=-22.388, g=-22.388\n",
      ">824, c1=7.789, c2=-22.371, g=-22.371\n",
      ">825, c1=8.009, c2=-22.367, g=-22.367\n",
      ">826, c1=7.728, c2=-22.364, g=-22.364\n",
      ">827, c1=8.000, c2=-22.353, g=-22.353\n",
      ">828, c1=7.911, c2=-22.282, g=-22.282\n",
      ">829, c1=7.910, c2=-22.234, g=-22.234\n",
      ">830, c1=7.804, c2=-22.250, g=-22.250\n",
      ">831, c1=7.733, c2=-22.230, g=-22.230\n",
      ">832, c1=7.970, c2=-22.259, g=-22.259\n",
      ">833, c1=7.932, c2=-22.266, g=-22.266\n",
      ">834, c1=7.878, c2=-22.242, g=-22.242\n",
      ">835, c1=7.637, c2=-22.227, g=-22.227\n",
      ">836, c1=7.764, c2=-22.251, g=-22.251\n",
      ">837, c1=7.927, c2=-22.224, g=-22.224\n",
      ">838, c1=7.833, c2=-22.208, g=-22.208\n",
      ">839, c1=7.731, c2=-22.180, g=-22.180\n",
      ">840, c1=7.878, c2=-22.151, g=-22.151\n",
      ">841, c1=7.855, c2=-22.125, g=-22.125\n",
      ">842, c1=7.654, c2=-22.133, g=-22.133\n",
      ">843, c1=7.646, c2=-22.094, g=-22.094\n",
      ">844, c1=7.647, c2=-22.093, g=-22.093\n",
      ">845, c1=7.794, c2=-22.079, g=-22.079\n",
      ">846, c1=7.716, c2=-22.055, g=-22.055\n",
      ">847, c1=7.845, c2=-22.043, g=-22.043\n",
      ">848, c1=7.698, c2=-22.024, g=-22.024\n",
      ">849, c1=7.818, c2=-22.026, g=-22.026\n",
      ">850, c1=7.964, c2=-22.060, g=-22.060\n",
      ">851, c1=7.807, c2=-22.051, g=-22.051\n",
      ">852, c1=7.806, c2=-22.065, g=-22.065\n",
      ">853, c1=7.811, c2=-22.062, g=-22.062\n",
      ">854, c1=7.844, c2=-22.014, g=-22.014\n",
      ">855, c1=7.805, c2=-21.998, g=-21.998\n",
      ">856, c1=7.736, c2=-21.973, g=-21.973\n",
      ">857, c1=7.679, c2=-21.957, g=-21.957\n",
      ">858, c1=7.578, c2=-21.945, g=-21.945\n",
      ">859, c1=7.883, c2=-21.926, g=-21.926\n",
      ">860, c1=7.799, c2=-21.904, g=-21.904\n",
      ">861, c1=7.800, c2=-21.887, g=-21.887\n",
      ">862, c1=7.906, c2=-21.852, g=-21.852\n",
      ">863, c1=7.496, c2=-21.874, g=-21.874\n",
      ">864, c1=7.652, c2=-21.854, g=-21.854\n",
      ">865, c1=7.810, c2=-21.836, g=-21.836\n",
      ">866, c1=7.722, c2=-21.812, g=-21.812\n",
      ">867, c1=7.630, c2=-21.797, g=-21.797\n",
      ">868, c1=7.685, c2=-21.807, g=-21.807\n",
      ">869, c1=7.542, c2=-21.832, g=-21.832\n",
      ">870, c1=7.740, c2=-21.823, g=-21.823\n",
      ">871, c1=7.520, c2=-21.806, g=-21.806\n",
      ">872, c1=7.711, c2=-21.786, g=-21.786\n",
      ">873, c1=7.620, c2=-21.763, g=-21.763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: generated_plot_0873.png and wgan_results\\model_0873.h5\n",
      ">874, c1=7.757, c2=-21.765, g=-21.765\n",
      ">875, c1=7.793, c2=-21.772, g=-21.772\n",
      ">876, c1=7.733, c2=-21.754, g=-21.754\n",
      ">877, c1=7.488, c2=-21.703, g=-21.703\n",
      ">878, c1=7.717, c2=-21.684, g=-21.684\n",
      ">879, c1=7.754, c2=-21.686, g=-21.686\n",
      ">880, c1=7.621, c2=-21.656, g=-21.656\n",
      ">881, c1=7.378, c2=-21.673, g=-21.673\n",
      ">882, c1=7.674, c2=-21.650, g=-21.650\n",
      ">883, c1=7.522, c2=-21.616, g=-21.616\n",
      ">884, c1=7.508, c2=-21.619, g=-21.619\n",
      ">885, c1=7.624, c2=-21.629, g=-21.629\n",
      ">886, c1=7.731, c2=-21.644, g=-21.644\n",
      ">887, c1=7.673, c2=-21.624, g=-21.624\n",
      ">888, c1=7.718, c2=-21.583, g=-21.583\n",
      ">889, c1=7.632, c2=-21.566, g=-21.566\n",
      ">890, c1=7.741, c2=-21.572, g=-21.572\n",
      ">891, c1=7.377, c2=-21.544, g=-21.544\n",
      ">892, c1=7.436, c2=-21.541, g=-21.541\n",
      ">893, c1=7.621, c2=-21.538, g=-21.538\n",
      ">894, c1=7.716, c2=-21.529, g=-21.529\n",
      ">895, c1=7.454, c2=-21.539, g=-21.539\n",
      ">896, c1=7.688, c2=-21.503, g=-21.503\n",
      ">897, c1=7.729, c2=-21.508, g=-21.508\n",
      ">898, c1=7.558, c2=-21.481, g=-21.481\n",
      ">899, c1=7.517, c2=-21.475, g=-21.475\n",
      ">900, c1=7.490, c2=-21.497, g=-21.497\n",
      ">901, c1=7.600, c2=-21.489, g=-21.489\n",
      ">902, c1=7.631, c2=-21.475, g=-21.475\n",
      ">903, c1=7.465, c2=-21.463, g=-21.463\n",
      ">904, c1=7.481, c2=-21.455, g=-21.455\n",
      ">905, c1=7.480, c2=-21.453, g=-21.453\n",
      ">906, c1=7.436, c2=-21.430, g=-21.430\n",
      ">907, c1=7.530, c2=-21.431, g=-21.431\n",
      ">908, c1=7.517, c2=-21.427, g=-21.427\n",
      ">909, c1=7.444, c2=-21.386, g=-21.386\n",
      ">910, c1=7.667, c2=-21.376, g=-21.376\n",
      ">911, c1=7.480, c2=-21.352, g=-21.352\n",
      ">912, c1=7.535, c2=-21.355, g=-21.355\n",
      ">913, c1=7.317, c2=-21.339, g=-21.339\n",
      ">914, c1=7.463, c2=-21.310, g=-21.310\n",
      ">915, c1=7.508, c2=-21.287, g=-21.287\n",
      ">916, c1=7.434, c2=-21.305, g=-21.305\n",
      ">917, c1=7.309, c2=-21.290, g=-21.290\n",
      ">918, c1=7.423, c2=-21.252, g=-21.252\n",
      ">919, c1=7.307, c2=-21.243, g=-21.243\n",
      ">920, c1=7.368, c2=-21.233, g=-21.233\n",
      ">921, c1=7.550, c2=-21.234, g=-21.234\n",
      ">922, c1=7.322, c2=-21.259, g=-21.259\n",
      ">923, c1=7.432, c2=-21.225, g=-21.225\n",
      ">924, c1=7.436, c2=-21.183, g=-21.183\n",
      ">925, c1=7.309, c2=-21.185, g=-21.185\n",
      ">926, c1=7.436, c2=-21.156, g=-21.156\n",
      ">927, c1=7.414, c2=-21.145, g=-21.145\n",
      ">928, c1=7.451, c2=-21.134, g=-21.134\n",
      ">929, c1=7.507, c2=-21.152, g=-21.152\n",
      ">930, c1=7.383, c2=-21.140, g=-21.140\n",
      ">931, c1=7.523, c2=-21.129, g=-21.129\n",
      ">932, c1=7.311, c2=-21.104, g=-21.104\n",
      ">933, c1=7.370, c2=-21.132, g=-21.132\n",
      ">934, c1=7.365, c2=-21.104, g=-21.104\n",
      ">935, c1=7.460, c2=-21.112, g=-21.112\n",
      ">936, c1=7.176, c2=-21.121, g=-21.121\n",
      ">937, c1=7.531, c2=-21.097, g=-21.097\n",
      ">938, c1=7.164, c2=-21.078, g=-21.078\n",
      ">939, c1=7.377, c2=-21.045, g=-21.045\n",
      ">940, c1=7.320, c2=-21.051, g=-21.051\n",
      ">941, c1=7.379, c2=-21.060, g=-21.060\n",
      ">942, c1=7.324, c2=-21.043, g=-21.043\n",
      ">943, c1=7.295, c2=-20.990, g=-20.990\n",
      ">944, c1=7.360, c2=-20.987, g=-20.987\n",
      ">945, c1=7.280, c2=-20.967, g=-20.967\n",
      ">946, c1=7.054, c2=-20.949, g=-20.949\n",
      ">947, c1=7.126, c2=-20.939, g=-20.939\n",
      ">948, c1=7.348, c2=-20.937, g=-20.937\n",
      ">949, c1=7.340, c2=-20.918, g=-20.918\n",
      ">950, c1=7.317, c2=-20.922, g=-20.922\n",
      ">951, c1=7.506, c2=-20.893, g=-20.893\n",
      ">952, c1=7.348, c2=-20.897, g=-20.897\n",
      ">953, c1=7.363, c2=-20.898, g=-20.898\n",
      ">954, c1=7.191, c2=-20.863, g=-20.863\n",
      ">955, c1=7.165, c2=-20.852, g=-20.852\n",
      ">956, c1=7.120, c2=-20.814, g=-20.814\n",
      ">957, c1=7.285, c2=-20.807, g=-20.807\n",
      ">958, c1=7.068, c2=-20.817, g=-20.817\n",
      ">959, c1=7.131, c2=-20.826, g=-20.826\n",
      ">960, c1=7.174, c2=-20.808, g=-20.808\n",
      ">961, c1=7.256, c2=-20.809, g=-20.809\n",
      ">962, c1=7.152, c2=-20.766, g=-20.766\n",
      ">963, c1=7.264, c2=-20.770, g=-20.770\n",
      ">964, c1=7.178, c2=-20.774, g=-20.774\n",
      ">965, c1=7.200, c2=-20.780, g=-20.780\n",
      ">966, c1=7.279, c2=-20.805, g=-20.805\n",
      ">967, c1=7.513, c2=-20.774, g=-20.774\n",
      ">968, c1=7.127, c2=-20.773, g=-20.773\n",
      ">969, c1=7.355, c2=-20.740, g=-20.740\n",
      ">970, c1=7.211, c2=-20.718, g=-20.718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved: generated_plot_0970.png and wgan_results\\model_0970.h5\n"
     ]
    }
   ],
   "source": [
    "# size of the latent space\n",
    "latent_dim = 50\n",
    "# create the critic\n",
    "critic = define_critic()\n",
    "# create the generator\n",
    "generator = define_generator(latent_dim)\n",
    "# create the gan\n",
    "gan_model = define_gan(generator, critic)\n",
    "# load image data\n",
    "dataset = load_real_samples()\n",
    "print(dataset.shape)\n",
    "# train model\n",
    "train(generator, critic, gan_model, dataset, latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9a9908-1835-4858-b5b5-c52c66fb49ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bbd0cc96",
   "metadata": {},
   "source": [
    "#### References\n",
    "1. [gans-in-action](https://github.com/GANs-in-Action/gans-in-action)\n",
    "2. [Machine Learning Mastery](https://machinelearningmastery.com/how-to-code-a-wasserstein-generative-adversarial-network-wgan-from-scratch/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc66b704",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
